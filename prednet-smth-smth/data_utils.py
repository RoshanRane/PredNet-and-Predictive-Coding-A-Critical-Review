#!/usr/bin/env python
# coding: utf-8
########################################## Importing libraries #####################################################import os, glob, sys
import os, glob, sys
import numpy as np
import pandas as pd

from matplotlib import pyplot as plt
from PIL import Image, ImageOps
from keras import backend as K
from keras_preprocessing.image import Iterator  # , load_img, img_to_array
import threading


########################################################################################################################


class SmthSmthSequenceGenerator(Iterator):
    '''
    Data generator that creates batched sequences from the smth-smth dataset for input into PredNet.
    info: to generate the data_csv, run the extract_20bn.py script first on the raw smth-smth videos.

    Args:

        dataframe : Can either be the path to the csv file generated by the extract_20bn.py or
        be a pandas df of the same csv
        
        nframes (optional): number of frames to use per video. If unspecified, the default 
        is calculated from the fps as {fps:nframes} - {12:36, 6:20, 3:10, 2:8, 1:5}
        The policy for selection of these frames can be further modified
        using the 'nframes_selection_mode' and 'reject_extremes'parameters.
        
        fps (optional): Allowed values are [1,2,3,6,12]. Default fps of the videos is 12. 
        
        split (optional): The split to use for training. Can be one of 'train', 'val', 'test'.

        target_im_size (optional): Provide a tuple of format (height,width). All video frames
        are resized to this shape. Default value is (128, 160).
        The height or width cannot be greater than this

        output_mode (optional): Used to control what is returned in y (label):
        if set to 'label' returns the label's template ID.
        if set to 'prediction' simply returns y = X.
        if set to 'error' returns a np.zeros() of same shape as x.

        nframes_selection_mode (optional): Can be one of "smth-smth-baseline-method" or "dynamic-fps"
        if set as "smth-smth-baseline-method",
        a) For num_of_frames < nframes : replicate the first and last frames.
        b) For num_of_frames > nframes : sample consecutive 'nframes' such that the sampled videos segments
        are mostly in the center of the whole video
        if set as "dynamic-fps",
        a) For num_of_frames < nframes : Artificially increase fps - Duplicate frames at the begining, end and in between the video to make it equal to nframes.
        b) For num_of_frames > nframes : Artificially decrease fps - Sample non-consecutive frames from the videos such that the total number of frames equal nframes.

        reject_extremes (optional): A tuple which says
            (reject-videos-with-nframes-lower-than-this, reject-videos-with-nframes-higher-than-this)
        Recommended to set to (12,84) that corresponds to 3 std. dev. for the smth-smth dataset and will
        rejects outliers in the dataset.

        img_interpolation (optional): PIL interpolation to use while resizing.
        allowed values are {'nearest', 'bicubic', 'bilinear', 'LANCZOS'}

        random_crop (optional): Data-augumentation. Flag to enable 'random-crop' by the width of the frames. The crop width is decided using
        a binomial distribution with max probability at the center of the frame.

        horizontal_flip (optional): Data-augumentation. Flag to enable random 'horizontal_flip' of videos.
        the labels are also changed appropriately.
        Ex. 'Pulling [something] from right to left' -> 'Pulling [something] from left to right' after flipping
    '''

    def __init__(self, dataframe
                 , nframes=None
                 , fps=12
                 , split=''
                 , batch_size=32
                 , target_im_size=(64, 80)
                 , img_interpolation='nearest'
                 , output_mode='error'
                 , nframes_selection_mode="smth-smth-baseline-method"
                 , reject_extremes=(None, None)
                 , random_crop=True
                 , horizontal_flip=False
                 , shuffle=True, seed=None
                 , data_format='channels_last'
                 , debug=False
                 ):

        if seed is not None:
            np.random.seed(seed)
        if (isinstance(dataframe, str)):
            df = pd.read_csv(dataframe)
        else:
            df = dataframe

        # select the split subset
        if (split):
            assert split in set(df['split']), "split can be one of ({}) only".format(set(df['split']))
            # select the split subset
            df = df[df['split'] == split]

        # select the subset of videos with nframes >= min_nframes and <= max_nframes
        min_nframes, max_nframes = reject_extremes
        if (min_nframes is not None):
            df_subset = df[df.num_of_frames >= min_nframes]
            if (len(df_subset) < 0.7 * len(df)):  # if more than 30% rejected then raise a WARNING
                print(
                    "SmthsmthGenerator WARNING: Rejecting videos less than {}-frames resulted in {:.0f}% of the videos({}) to be discarded.".format(
                        min_nframes, float(len(df_subset)) * 100 / len(df), len(df_subset)))
            df = df_subset
        if (max_nframes is not None):
            df_subset = df[df.num_of_frames <= max_nframes]
            if (len(df_subset) < 0.7 * len(df)):  # if more than 30% rejected then raise a WARNING
                print(
                    "SmthsmthGenerator WARNING: Rejecting videos more than {}-frames resulted in {:.0f}% of the videos({}) to be discarded.".format(
                        max_nframes, float(len(df_subset)) * 100 / len(df), len(df_subset)))
            df = df_subset

        assert output_mode in {'error', 'prediction', 'label'}, 'output_mode must be in {error, prediction, label}'
        self.output_mode = output_mode
        assert len(target_im_size) == 2, "Invalid 'target_im_size'. It should be a tuple of format (height, width)"
        assert (target_im_size[0] <= min(df.height)) and (target_im_size[1] <= min(df.width)), "Invalid 'target_im_size'.\
(height, width) cannot be greater than the ({:.0f},{:.0f}) which is the minimum in the dataset".format(min(df.height),
                                                                                                       min(df.width))
        self.df = df.reset_index(drop=True)
        self.target_im_size = target_im_size
        self.batch_size = batch_size
                
        assert nframes_selection_mode in {
            "smth-smth-baseline-method", "dynamic-fps"
        }, 'nframes_selection_mode must be one of {"smth-smth-baseline-method", "dynamic-fps"}'
        self.nframes_selection_mode = nframes_selection_mode
        if(fps!=12 and nframes_selection_mode=="dynamic-fps"):
            print("SmthsmthGenerator WARNING. Value passed to fps is ignored when 'nframes_selection_mode' is set as 'dynamic-fps'")
        assert nframes_selection_mode!="dynamic-fps" or nframes is not None,"when 'nframes_selection_mode' is set as 'dynamic-fps' then nframes must be specified and cannot be 'None'. "
        
        assert fps in [1,2,3,6,12], "allowed values for fps are [1,3,6,12] for this dataset. But given {}".format(fps)
        self.fps_ratio = 12//fps
        
        if(nframes is None):
            fps_to_nframes = {12:36, 6:20, 3:10, 2:8, 1:5}
            nframes = fps_to_nframes[fps]
            print("{} nframes/video set by default.".format(nframes))
            
        self.nframes = nframes
        
        _PIL_INTERPOLATION_METHODS = {
            'LANCZOS': Image.LANCZOS,
            'nearest': Image.NEAREST,
            'bilinear': Image.BILINEAR,
            'bicubic': Image.BICUBIC
        }
        assert img_interpolation in _PIL_INTERPOLATION_METHODS.keys(), "Allowed values for 'img_interpolation' are {}".format(
            set(_PIL_INTERPOLATION_METHODS.keys()))
        self.img_interpolation = _PIL_INTERPOLATION_METHODS[img_interpolation]
        self.horizontal_flip = horizontal_flip
        if (self.horizontal_flip):
            # if we flip, some labels need to be remapped which contain these orientation information
            self.some_label_remaps = {166: 167, 167: 166, 93: 94, 94: 93, 86: 87, 87: 86}
        self.random_crop = random_crop
        self.shuffle = shuffle
        self.seed = seed
        self.debug = debug
        if (data_format != 'channels_last'):
            raise NotImplementedError("Only 'channels_last' data_format is currently supported.\
{} option is not supported".format(data_format))

        super(SmthSmthSequenceGenerator, self).__init__(n=len(self.df),
                                                        batch_size=batch_size,
                                                        shuffle=shuffle,
                                                        seed=seed)

    def _get_batches_of_transformed_samples(self, index_array):

        batch_x = np.empty(((len(index_array),) + (self.nframes,) + self.target_im_size + (3,))
                           , dtype=np.float32)
        # to store which videos have been horizontally flipped. Needed for output mode 'label'
        hor_flipped = np.empty(len(index_array), )

        for i, idx in enumerate(index_array):
            # read the video dir
            vid_dir = self.df.loc[idx, 'path']
            batch_x[i], hor_flipped[i] = self.fetch_and_preprocess(vid_dir, self.target_im_size)

        if self.output_mode == 'error':  # model outputs errors, so y should be zeros
            batch_y = np.zeros(self.batch_size, np.float32)
        elif self.output_mode == 'prediction':  # output actual pixels
            batch_y = batch_x
        elif self.output_mode == 'label':
            batch_y = np.asarray(self.df.loc[index_array, "template_id"])
            if (self.horizontal_flip):
                # remap the effected horizontally flipped labels
                for i in range(len(batch_y)):
                    if (hor_flipped[i]) and (batch_y[i] in self.some_label_remaps.keys()):
                        if (self.debug): print("idx {}: label {} replaced with {}".format(i, batch_y[i],
                                                                                          self.some_label_remaps[
                                                                                              batch_y[i]]))
                        batch_y[i] = self.some_label_remaps[batch_y[i]]
        else:
            raise NotImplementedError
            
        return batch_x, batch_y

    def fetch_and_preprocess(self, vid_dir, target_im_size):
        #read the fps if specified
        frames = sorted(glob.glob(vid_dir + "/*.png"))[::self.fps_ratio]
        
        total_frames = len(frames)
        # select exactly 'nframes' from each video dir... preprocessing (4)
        if (self.nframes_selection_mode == "smth-smth-baseline-method"):
            if (total_frames > self.nframes):
                # sample the start frame using a binomial distribution highest probability at the center of the video
                start_frame_idx = np.random.binomial((total_frames - self.nframes), p=0.5)
                frames_out = frames[start_frame_idx: start_frame_idx + self.nframes]
            elif (total_frames < self.nframes):
                # replicate the first frame and last frame at the ends to match self.nframes
                rep_begin = np.random.binomial((self.nframes - total_frames), p=0.5)
                rep_end = (self.nframes - (total_frames + rep_begin))
                frames_out = [frames[0]] * (rep_begin) + frames + [frames[-1]] * (rep_end)
            else:  # total_frames == self.nframes
                frames_out = frames

        else:  # (self.nframes_selection_mode == "dynamic-fps"):
            if (total_frames > self.nframes):
                # delete frames at regular intervals until exactly nframes are left
                if (self.debug):
                    print("total_frames=", total_frames, "frames_excess=", (total_frames - self.nframes))
                frames_out = frames
                delete_rate = (total_frames // (total_frames - self.nframes))
                deleted = 0
                i = 0  # start by first replicating the 0th frame
                while (len(frames_out) > self.nframes):
                    del_idx = i * delete_rate - deleted
                    if (self.debug):
                        print("removing frame at idx", del_idx)
                    del frames_out[del_idx]
                    i += 1
                    deleted += 1

            elif (total_frames < self.nframes):
                # duplicate frames at regular intervals until exactly nframes are left
                if (self.debug):
                    print("total_frames=", total_frames, "frames_shortage=", (self.nframes - total_frames))
                frames_out = frames
                insert_rate = (total_frames // (self.nframes - total_frames))
                inserted = 0
                i = 0  # start by first replicating the 0th frame
                while (len(frames_out) < self.nframes):
                    dup_idx = i * insert_rate + inserted
                    if (self.debug):
                        print("duplicating frame at idx", dup_idx)
                    frames_out.insert(dup_idx, frames[dup_idx])
                    i += 1
                    inserted += 1

            else:  # total_frames == self.nframes
                frames_out = frames

        ### load_vid using keras built-in function
        #         X = np.empty(((self.nframes,) + target_im_size + (3,)), dtype=np.float32)
        #         for i,frame in enumerate(frames_out):
        #             X[i] = img_to_array(load_img(frame, target_size=target_im_size))
        X, hor_flip = self.load_vid(frames_out, target_im_size)
        # rescale
        X = X / 255.

        return X, hor_flip

    def load_vid(self, frames, target_im_size):

        X = np.empty(((self.nframes,) + target_im_size + (3,)), dtype=np.float32)
        target_h, target_w = target_im_size
        if (self.horizontal_flip):
            # flip coin to randomly perform horizontal flipping
            flip = np.random.randint(0, 2)
        else:
            flip = False

        if (self.debug):
            debug_print_once = True
        else:
            debug_print_once = False

        w_crop_flag = True  # calculate the width crop edges only once

        for i, frame in enumerate(frames):
            im = Image.open(frame)
            if (debug_print_once): print("original im shape (W X H)=", im.size)

            if (self.random_crop):
                w_same_aspect = int((target_h / im.height) * im.width)
                # resize such that the aspect ratio is conserved for later random cropping
                if (w_same_aspect > target_w):
                    im = im.resize((w_same_aspect, target_h),
                                   self.img_interpolation)
                    # width-cropping
                    if (w_crop_flag):
                        w_crop = np.random.binomial((im.width - target_w), p=0.5)
                        w_crop_flag = False
                    if (debug_print_once): print(
                        "({},{}) width cropped on left and right resp.".format(w_crop, im.width - w_crop - target_w))
                    im = im.crop((w_crop, 0, target_w + w_crop, im.height))
                else:
                    im = im.resize((target_w, target_h),
                                   self.img_interpolation)
            else:
                im = im.resize((target_w, target_h),
                               self.img_interpolation)
            if (flip):
                if (debug_print_once): print("Horizontal flipping performed")
                im = ImageOps.mirror(im)
            if (debug_print_once):
                print("im resized shape", im.size)
                debug_print_once = False  # turn off for this video's remaining frames
            # move axis and store the array in X
            X[i] = np.asarray(im, dtype=np.float32)

        return X, flip

    def next(self):
        """For python 2.x. # Returns  The next batch.
        info : function taken directly from keras_preprocessing.DataFrameIterator class
        """
        # Keeps under lock only the mechanism which advances
        # the indexing of each batch.
        with self.lock:
            index_array = next(self.index_generator)
            # A bug in keras.Iterator class causes it to sometimes return index_array of size < batch_size
            # This occurs at the end of the entire dataset 
            if(len(index_array)!=self.batch_size ):
                index_array = next(self.index_generator)                
        # The transformation of images is not under thread lock
        # so it can be done in parallel
        return self._get_batches_of_transformed_samples(index_array)

    def __len__(self):
        return len(self.df)//self.batch_size


# In[71]:

if __name__ == '__main__':
    # TEST : runs the generator 10 times and prints out the output dimension of the batches returned
    # GUIDE : how to use the class

    data_csv = "/data/videos/something-something-v2/preprocessed/data.csv"
    val_gen = SmthSmthSequenceGenerator(data_csv
                                , nframes=48
                                , split="val"
                                , batch_size=8
                                , target_im_size=(64, 80)
                                , shuffle=True, seed=42
                                #                                       , reject_extremes = (16, 80)
                                , output_mode="label"
                                , random_crop=False
                                , horizontal_flip=True
                                , img_interpolation='bilinear'
                                #                                   , debug = True
                                #                                   , nframes_selection_mode = "dynamic-fps"
                                )
    print("shape of the next 10 generator outputs:")
    for i in range(5):
        batch, label = next(val_gen)
        print("Batch shape =", batch.shape)
        print("label shape =", label.shape)

    from viz_utils import plot_video

    # visualize one video
    plot_video(next(val_gen)[0][0], save_pdf=True, stats=True)