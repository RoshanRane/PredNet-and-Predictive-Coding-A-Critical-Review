#!/usr/bin/env python
# coding: utf-8


# import os
# os.environ["CUDA_VISIBLE_DEVICES"]="0,1"


import os, glob, sys
import numpy as np
import pandas as pd
# from matplotlib import pyplot as plt
from PIL import Image as pil_image
from keras import backend as K
from keras_preprocessing.image import Iterator, load_img, img_to_array
import threading

class SmthsmthGenerator(Iterator):    
    '''
    Data generator that creates batched sequences from the smth-smth dataset for input into PredNet.
    info: to generate the data_csv, run the extract_20bn.py script first on the raw smth-smth videos.
    
    Args:
    
        dataframe : Can either be the path to the csv file generated by the extract_20bn.py or 
        be a pandas df of the same csv

        nframes : number of frames to use per video. The policy for selection of these frames can be modified 
        using the nframes_selection_mode parameter
        
        split (optional): The split to use for training. Can be one of 'train', 'val', 'test'.
        
        target_im_size (optional): Provide a tuple of format (height,width). All video frames
        are resized to this shape. Default value is (128, 160). 
        The height or width cannot be greater than this
        
        output_mode (optional): <todo>
        
        nframes_selection_mode (optional): Can be one of "smth-smth-baseline-method" or "dynamic-fps"
        if set as "smth-smth-baseline-method",
        a) For videos < nframes  : replicate the first and last frames.  
        b) For videos > nframes  : sample consecutive 'nframes' such that the sampled videos segments 
        are mostly in the center of the whole video
        if set as "dynamic-fps", <to-do>
        a) For videos < nframes  : Artificially increase fps - Duplicate frames at the begining, end and in between the video to make it equal to nframes.  
        b) For videos > nframes  : Artificially decrease fps - Sample non-consecutive frames from the videos such that the total number of frames equal nframes.
        
        reject_extremes (optional): A tuple which says 
            (reject-videos-with-nframes-lower-than-this, reject-videos-with-nframes-higher-than-this)
        Recommended to set to (10,64) that corresponds to 3 std. dev. for the smth-smth dataset and will
        rejects outliers in the dataset. 
    '''    
    def __init__(self, dataframe
                 , nframes
                 , split = ''
                 , batch_size=8
                 , target_im_size = (128,160)
#                  , img_interpolation='nearest'
                 , output_mode='error'
                 , nframes_selection_mode = "smth-smth-baseline-method"
                 , reject_extremes = (None, None)
                 , shuffle=True, seed=None
                 , data_format='channels_last'
                 , debug = False
                ):
     
        if seed is not None:
            np.random.seed(seed)
        if(isinstance(dataframe,str)):
            df = pd.read_csv(dataframe)    
        else:
            df = dataframe
        
        # select the split subset
        if(split):
            assert split in set(df['split']), "split can be one of ({}) only".format(set(df['split']))
            # select the split subset
            df = df[df['split'] == split]
        
        # select the subset of videos with nframes >= min_nframes and <= max_nframes
        min_nframes, max_nframes = reject_extremes
        if(min_nframes is not None):
            df_subset = df[df.num_of_frames >= min_nframes]
            if(len(df_subset) < 0.7*len(df)) : # if more than 30% rejected then raise a WARNING
                print("WARNING: Rejecting videos less than {}-frames resulted in {:.0f}% of the videos({}) to be discarded.".format(
                    min_nframes, float(len(df_subset))*100/len(df), len(df_subset)))
            df = df_subset
        if(max_nframes is not None): 
            df_subset = df[df.num_of_frames <= max_nframes] 
            if(len(df_subset) < 0.7*len(df)) :  # if more than 30% rejected then raise a WARNING
                print("WARNING: Rejecting videos more than {}-frames resulted in {:.0f}% of the videos({}) to be discarded.".format(
                    max_nframes, float(len(df_subset))*100/len(df), len(df_subset)))
            df = df_subset 

        assert output_mode in {'error', 'prediction'}, 'output_mode must be in {error, prediction}'
        self.output_mode = output_mode
        assert len(target_im_size) == 2, "Invalid 'target_im_size'. It should be a tuple of format (height, width)" 
        assert (target_im_size[0] <= min(df.height))and (target_im_size[1] <= min(df.width)), "Invalid 'target_im_size'.\
(height, width) cannot be greater than the ({:.0f},{:.0f}) which is the minimum in the dataset".format(min(df.height),min(df.width)) 
        self.df = df.reset_index(drop=True)
        self.target_im_size = target_im_size
        self.batch_size = batch_size
        self.nframes = nframes
        self.shuffle = shuffle
        self.seed = seed
        self.debug = debug
        if(data_format != 'channels_last'): 
            raise NotImplementedError("Only 'channels_last' data_format is currently supported.\
{} option is not supported".format(data_format))
            
        assert nframes_selection_mode in {
            "smth-smth-baseline-method","dynamic-fps"
        }, 'nframes_selection_mode must be one of {"smth-smth-baseline-method", "dynamic-fps"}'
        self.nframes_selection_mode = nframes_selection_mode
        
        super(SmthsmthGenerator, self).__init__(n = len(self.df),
                                        batch_size=batch_size,
                                        shuffle=shuffle, 
                                        seed=seed)
        
    
    def _get_batches_of_transformed_samples(self, index_array):        
        
        batch_x = np.empty(((len(index_array),) +  (self.nframes,) + self.target_im_size + (3,))
                           , dtype=np.float32)
        
        for i, idx in enumerate(index_array):
            # read the video dir
            vid_dir = self.df.loc[idx, 'path']
            batch_x[i] = self.fetch_and_preprocess(vid_dir, self.target_im_size)
            
        if self.output_mode == 'error':  # model outputs errors, so y should be zeros
            batch_y = np.zeros(self.batch_size, np.float32)
        elif self.output_mode == 'prediction':  # output actual pixels
            batch_y = batch_x
        else:
            raise NotImplementedError
            
        return batch_x, batch_y
    
    def fetch_and_preprocess(self, vid_dir, target_im_size):
        
        frames = sorted(glob.glob(vid_dir+"/*.png"))
        total_frames = len(frames)
        # select exactly 'nframes' from each video dir... preprocessing (4)
        if(self.nframes_selection_mode == "smth-smth-baseline-method"):
            if(total_frames > self.nframes):
                # sample the start frame using a binomial distribution highest probability at the center of the video
                start_frame_idx = np.random.binomial((total_frames - self.nframes), p =0.5) 
                frames_out = frames[start_frame_idx: start_frame_idx + self.nframes]
            elif(total_frames < self.nframes):
                # replicate the first frame and last frame at the ends to match self.nframes
                replicate_cnt_start = (self.nframes - total_frames)//2
                replicate_cnt_end = (self.nframes - (total_frames + replicate_cnt_start))
                frames_out = [frames[0]]*(replicate_cnt_start) + frames + [frames[-1]]*(replicate_cnt_end) 
            else: #total_frames == self.nframes
                frames_out = frames
                
        else:#(self.nframes_selection_mode == "dynamic-fps"):
            if(total_frames > self.nframes):
                # delete frames at regular intervals until exactly nframes are left
                if(self.debug):
                    print("total_frames=",total_frames,"frames_excess=",(total_frames - self.nframes))
                frames_out = frames
                delete_rate = (total_frames//(total_frames - self.nframes))
                deleted = 0
                i = 0 #start by first replicating the 0th frame
                while(len(frames_out) > self.nframes):
                    del_idx = i*delete_rate - deleted
                    if(self.debug):
                        print("removing frame at idx",del_idx)
                    del frames_out[del_idx]
                    i += 1
                    deleted += 1
                
            elif(total_frames < self.nframes):               
                # duplicate frames at regular intervals until exactly nframes are left
                if(self.debug):
                    print("total_frames=",total_frames,"frames_shortage=",(self.nframes - total_frames))
                frames_out = frames
                insert_rate = (total_frames//(self.nframes - total_frames))
                inserted = 0
                i = 0 #start by first replicating the 0th frame
                while(len(frames_out) < self.nframes):
                    dup_idx = i*insert_rate + inserted
                    if(self.debug):
                        print("duplicating frame at idx",dup_idx)
                    frames_out.insert(dup_idx, frames[dup_idx])
                    i += 1
                    inserted += 1
                    
            else: #total_frames == self.nframes
                frames_out = frames      
                
        X = np.empty(((self.nframes,) + target_im_size + (3,)), dtype=np.float32)
            
        for i,frame in enumerate(frames_out):
#             X[i] = self.load_img(frame, target_size= target_im_size)
            X[i] = img_to_array(load_img(frame, target_size=target_im_size)) 
        X = self.preprocess(X)
    
        return X
    
    
    def load_img(self, img_dir, target_size):
#       _PIL_INTERPOLATION_METHODS = {
#         'nearest': pil_image.NEAREST,
#         'bilinear': pil_image.BILINEAR,
#         'bicubic': pil_image.BICUBIC,
# }
        im = pil_image.open(img_dir)
        w, h = im.size
        w_same_aspect =  int((target_size[0]/h)*w)
        im = im.resize((target_size[0], w_same_aspect), pil_image.ANTIALIAS)

        w_crop = (im.size[1] - target_size[1]) // 2
        im = im.crop((0, w_crop, im.size[0], target_size[1]+w_crop))
        im_arr = np.asarray(im, dtype=np.float32)
        im_arr = np.moveaxis(im_arr, 0, 1)
        return im_arr    
    
    
    def preprocess(self, X):
#         self.image_data_generator = ImageDataGenerator(
#                                     featurewise_center=False
#                                      , samplewise_center=False
#                                      , featurewise_std_normalization=False
#                                      , samplewise_std_normalization=False
#                                      , zca_whitening=False
#                                      , zca_epsilon=1e-06
#                                      , rotation_range=0
#                                      , width_shift_range=0.0
#                                      , height_shift_range=0.0
#                                      , brightness_range=None
#                                      , shear_range=0.0
#                                      , zoom_range=0.0
#                                      , channel_shift_range=0.0
#                                      , fill_mode='nearest'
#                                      , cval=0.0
#                                      , horizontal_flip=True
#                                      , vertical_flip=False
#                                      , rescale=1./255
#                                      , preprocessing_function=None
#                                      , data_format='channels_last'
#                                      , validation_split=0.0
#                                      , dtype='float32'
#                                     )
#         X = self.image_data_generator.standardize(X) # standardize to range [0,1]... preprocessing 3
#         params = {'flip_horizontal':True}
#         X = self.image_data_generator.apply_transform(X, params)
        return X / 255

    def next(self):
        """For python 2.x. # Returns  The next batch.
        info : function taken directly from keras_preprocessing.DataFrameIterator class
        """
        # Keeps under lock only the mechanism which advances
        # the indexing of each batch.
        with self.lock:
            index_array = next(self.index_generator)
        # The transformation of images is not under thread lock
        # so it can be done in parallel
        return self._get_batches_of_transformed_samples(index_array)
                      
    def __len__(self):
        return len(self.df)


# In[71]:

if __name__ == '__main__':
    # TEST : runs the generator 10 times and prints out the output dimension of the batches returned
    # GUIDE : how to use the class

    data_csv = "/data/videos/something-something-v2/preprocessed/data.csv"
    val_gen = SmthsmthGenerator(data_csv
                                      , nframes=48
                                      , split = "val"
                                      , batch_size=8
                                      , target_im_size = (128,224)
                                      , shuffle=True, seed=42
                                      , nframes_selection_mode = "smth-smth-baseline-method"
                                     )
    print("shape of the next 10 generator outputs:")
    for i in range(10):
        batch,label = next(val_gen)
        print("Batch shape =", batch.shape)
        print("label shape =", label.shape)

    # visualize some frames
    # frames = next(val_gen)[0]
    # f = plt.subplots()
    # for frm in frames:
    #     print("(shape, min, mean, max) =",frm.shape ,np.min(frm), np.mean(frm), np.max(frm))
    #     plt.imshow(frm)
    #     plt.show() 
