{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, glob, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image as pil_image\n",
    "from keras import backend as K\n",
    "from keras_preprocessing.image import get_keras_submodule\n",
    "import threading\n",
    "\n",
    "try:\n",
    "    IteratorType = get_keras_submodule('utils').Sequence\n",
    "except ImportError:\n",
    "    IteratorType = object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myIterator(IteratorType):\n",
    "    \"\"\"Base class for image data iterators from keras_preprocessing.image\n",
    "    modified for our multiple-crop size purpose.\n",
    "\n",
    "    # Arguments\n",
    "        n: Integer, total number of samples in the dataset to loop over.\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        seed: Random seeding for data shuffling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, batch_size, shuffle, seed, grps_boundary=None):\n",
    "        '''The grps_boundaries is used to define sub-groups within the whole sample group.'''\n",
    "        self.n = n\n",
    "        self.batch_size = batch_size   \n",
    "        \n",
    "        assert (grps_boundary is None) or (grps_boundary<=self.n), \"The index 'grps_boundary' must be less than n (number of samples)\"\n",
    "        self.boundary = grps_boundary\n",
    "        if(self.boundary is None):\n",
    "            self.total_batches = self.n//self.batch_size  \n",
    "        else:\n",
    "            self.total_batches = ((self.boundary//self.batch_size)  + (self.n - self.boundary)//self.batch_size) \n",
    "        \n",
    "        self.seed = seed\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_index = 0\n",
    "        self.total_batches_seen = 0\n",
    "        self.lock = threading.Lock()\n",
    "        self.index_array = None\n",
    "        self.index_generator = self._flow_index()\n",
    "\n",
    "    def _set_index_array(self):\n",
    "        self.index_array = np.arange(self.n)\n",
    "        if self.shuffle:\n",
    "            if(self.boundary is None):\n",
    "                self.index_array = np.random.choice(\n",
    "                    self.index_array\n",
    "                    , size=(self.total_batches, self.batch_size)\n",
    "                    , replace=False\n",
    "                )\n",
    "            else:\n",
    "                # when there are 2 sub-grps shuffle then seperately and then create their batches at indexes\n",
    "                self.index_array = np.append(\n",
    "                    np.random.choice(\n",
    "                        self.index_array[:self.boundary]\n",
    "                    , size=(self.boundary//self.batch_size, self.batch_size)\n",
    "                    , replace=False)\n",
    "                    , np.random.choice(\n",
    "                        self.index_array[self.boundary:]\n",
    "                    , size=((self.n - self.boundary)//self.batch_size, self.batch_size)\n",
    "                    , replace=False)\n",
    "                , axis = 0)\n",
    "                np.random.shuffle(self.index_array)\n",
    "                \n",
    "#         print(self.index_array)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise ValueError('Asked to retrieve element {idx}, '\n",
    "                             'but the Sequence '\n",
    "                             'has length {length}'.format(idx=idx,\n",
    "                                                          length=len(self)))\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed + self.total_batches_seen)\n",
    "        self.total_batches_seen += 1\n",
    "        \n",
    "        index_array = self.index_array[idx]\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_batches  \n",
    "\n",
    "    # check if epoch_end has been reached. If yes, reset the iterator and shuffle the data\n",
    "    def on_epoch_end(self):\n",
    "        self._set_index_array()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_index = 0\n",
    "\n",
    "    def _flow_index(self):\n",
    "        # Ensure self.batch_index is 0.\n",
    "        self.reset()\n",
    "        while 1:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed + self.total_batches_seen)\n",
    "            if(self.batch_index == 0):\n",
    "                self._set_index_array()\n",
    "                \n",
    "            cur_batch_index = self.batch_index\n",
    "            # increment batch index for next iter\n",
    "            if self.batch_index < (self.total_batches -1):\n",
    "                self.batch_index += 1\n",
    "            else:\n",
    "                self.batch_index = 0\n",
    "                \n",
    "            self.total_batches_seen += 1\n",
    "            \n",
    "            yield self.index_array[cur_batch_index]\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Needed if we want to do something like:\n",
    "        # for x, y in data_gen.flow(...):\n",
    "        return self\n",
    "\n",
    "    def __next__(self, *args, **kwargs):\n",
    "#         return next(self.index_generator)\n",
    "        return self.next(*args, **kwargs)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \"\"\"Gets a batch of transformed samples.\n",
    "        # Arguments\n",
    "            index_array: Array of sample indices to include in batch.\n",
    "        # Returns\n",
    "            A batch of transformed samples.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CODE\n",
    "\n",
    "# iterator = myIterator(n=23,batch_size=4, seed=42, shuffle=True, grps_boundary=13)\n",
    "# iterator._set_index_array()\n",
    "# print(iterator.total_batches)\n",
    "# for i, idxs in enumerate(iterator):\n",
    "#     print(idxs)\n",
    "#     if(i>20):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmthsmthGenerator(myIterator):    \n",
    "    '''\n",
    "    Data generator that creates batched sequences from the smth-smth dataset for input into PredNet.\n",
    "    info: to generate the data_csv, run the extract_20bn.py script first on the raw smth-smth videos.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        dataframe : Can either be the path to the csv file generated by the extract_20bn.py or \n",
    "        be a pandas df of the same csv\n",
    "\n",
    "        nframes : number of frames to use per video. The policy for selection of these frames can be modified \n",
    "        using the nframes_selection_mode parameter\n",
    "        \n",
    "        split (optional): The split to use for training. Can be one of 'train', 'val', 'test'.\n",
    "        \n",
    "        output_mode (optional): <todo>\n",
    "        \n",
    "        nframes_selection_mode (optional): Can be one of \"smth-smth-baseline-method\" or \"dynamic-fps\"\n",
    "        if set as \"smth-smth-baseline-method\",\n",
    "        a) For videos < nframes  : replicate the first and last frames.  \n",
    "        b) For videos > nframes  : sample consecutive 'nframes' such that the sampled videos segments \n",
    "        are mostly in the center of the whole video\n",
    "        if set as \"dynamic-fps\", <to-do>\n",
    "        a) For videos < nframes  : Artificially increase fps - Duplicate frames at the begining, end and in between the video to make it equal to nframes.  \n",
    "        b) For videos > nframes  : Artificially decrease fps - Sample non-consecutive frames from the videos such that the total number of frames equal nframes.\n",
    "        \n",
    "        reject_extremes (optional): A tuple which says \n",
    "            (reject-videos-with-nframes-lower-than-this, reject-videos-with-nframes-higher-than-this)\n",
    "        Recommended to set to (10,64) that corresponds to 3 std. dev. for the smth-smth dataset and will\n",
    "        rejects outliers in the dataset. \n",
    "    '''    \n",
    "    def __init__(self, dataframe\n",
    "                 , nframes\n",
    "                 , split = ''\n",
    "                 , batch_size=8\n",
    "                 , shuffle=True, seed=None\n",
    "                 , output_mode='error'\n",
    "                 , nframes_selection_mode = \"smth-smth-baseline-method\"\n",
    "                 , reject_extremes = (None, None)\n",
    "                 , debug = False\n",
    "#                  , img_interpolation='nearest'\n",
    "                 , data_format=K.image_data_format()\n",
    "                ):\n",
    "     \n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        if(isinstance(dataframe,str)):\n",
    "            df = pd.read_csv(dataframe)    \n",
    "        else:\n",
    "            df = dataframe\n",
    "        \n",
    "        # select the split subset\n",
    "        if(split):\n",
    "            assert split in set(df['split']), \"split can be one of ({}) only\".format(set(df['split']))\n",
    "            # select the split subset\n",
    "            df = df[df['split'] == split]\n",
    "        \n",
    "        # select the subset of videos with nframes >= min_nframes and <= max_nframes\n",
    "        min_nframes, max_nframes = reject_extremes\n",
    "        if(min_nframes is not None):\n",
    "            df_subset = df[df.num_of_frames >= min_nframes]\n",
    "            if(len(df_subset) < 0.7*len(df)) : # if more than 30% rejected then raise a WARNING\n",
    "                print(\"WARNING: Rejecting videos less than {}-frames resulted in {:.0f}% of the videos({}) to be discarded.\".format(\n",
    "                    min_nframes, float(len(df_subset))*100/len(df), len(df_subset)))\n",
    "            df = df_subset\n",
    "        if(max_nframes is not None): \n",
    "            df_subset = df[df.num_of_frames <= max_nframes] \n",
    "            if(len(df_subset) < 0.7*len(df)) :  # if more than 30% rejected then raise a WARNING\n",
    "                print(\"WARNING: Rejecting videos more than {}-frames resulted in {:.0f}% of the videos({}) to be discarded.\".format(\n",
    "                    max_nframes, float(len(df_subset))*100/len(df), len(df_subset)))\n",
    "            df = df_subset \n",
    "            \n",
    "        # sort them by the crop group\n",
    "        self.df = df.sort_values(by=['crop_group']).reset_index(drop=True)\n",
    "        # required to initialize the parent myIterator class\n",
    "        self.grp1_boundary = len(self.df[self.df['crop_group']==1])     \n",
    "\n",
    "        assert output_mode in {'error', 'prediction'}, 'output_mode must be in {error, prediction}'\n",
    "        self.output_mode = output_mode\n",
    "        self.batch_size = batch_size\n",
    "        self.nframes = nframes\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        self.debug = debug\n",
    "        if(data_format != 'channels_last'): \n",
    "            raise NotImplementedError(\"Only 'channels_last' data_format is currently supported by this class.\\\n",
    "'channels_first' is not supported\")\n",
    "            \n",
    "        assert nframes_selection_mode in {\n",
    "            \"smth-smth-baseline-method\",\"dynamic-fps\"\n",
    "        }, 'nframes_selection_mode must be one of {\"smth-smth-baseline-method\", \"dynamic-fps\"}'\n",
    "        self.nframes_selection_mode = nframes_selection_mode\n",
    "        \n",
    "        super(SmthsmthGenerator, self).__init__(n = len(self.df),\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=shuffle, \n",
    "                                        seed=seed,\n",
    "                                        grps_boundary = self.grp1_boundary)\n",
    "#         if N_seq is not None and len(self.df) > N_seq:  # select a subset of sequences if want to\n",
    "#             self.df = self.df[:N_seq]        \n",
    "#         if shuffle:\n",
    "#             self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#         self.X = hkl.load(data_file)  # X will be a 4D array of (n_images, nb_cols, nb_rows, nb_channels)        \n",
    "    \n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        \n",
    "        # check which crop size group is expected...preprocessing (1)\n",
    "        if(all(index_array < self.grp1_boundary)):\n",
    "            target_im_size = (128,160)\n",
    "        elif(all(index_array >= self.grp1_boundary)):\n",
    "            target_im_size = (128,224)\n",
    "        else:\n",
    "            raise ValueError(\"index_array {} contains a mix of both groups.\\\n",
    "They should all be either less than {} or greater than {}\".format(\n",
    "                index_array, self.grp1_boundary, self.grp1_boundary-1))\n",
    "        \n",
    "#         # 'channels_first' or 'channels_last'?\n",
    "#         if(self.data_format == 'channels_last'):\n",
    "        batch_x = np.empty(((len(index_array),) +  (self.nframes,) + target_im_size + (3,))\n",
    "                           , dtype=np.float32)\n",
    "#         else:\n",
    "#             batch_x = np.empty(((len(index_array),) + (3,) +  (self.nframes,) + self.im_shape)\n",
    "#                                , dtype=np.float32)       \n",
    "\n",
    "        for i, idx in enumerate(index_array):\n",
    "            # read the video dir\n",
    "            vid_dir = self.df.loc[idx, 'path']\n",
    "            batch_x[i] = self.fetch_and_preprocess(vid_dir, target_im_size)\n",
    "        if self.output_mode == 'error':  # model outputs errors, so y should be zeros\n",
    "            batch_y = np.zeros(self.batch_size, np.float32)\n",
    "        elif self.output_mode == 'prediction':  # output actual pixels\n",
    "            batch_y = batch_x\n",
    "            \n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def fetch_and_preprocess(self, vid_dir, target_im_size):\n",
    "        \n",
    "        frames = sorted(glob.glob(vid_dir+\"/*.png\"))\n",
    "        total_frames = len(frames)\n",
    "        # select exactly 'nframes' from each video dir... preprocessing (4)\n",
    "        if(self.nframes_selection_mode == \"smth-smth-baseline-method\"):\n",
    "            if(total_frames > self.nframes):\n",
    "                # sample the start frame using a binomial distribution highest probability at the center of the video\n",
    "                start_frame_idx = np.random.binomial((total_frames - self.nframes), p =0.5) \n",
    "                frames_out = frames[start_frame_idx: start_frame_idx + self.nframes]\n",
    "            elif(total_frames < self.nframes):\n",
    "                # replicate the first frame and last frame at the ends to match self.nframes\n",
    "                replicate_cnt_start = (self.nframes - total_frames)//2\n",
    "                replicate_cnt_end = (self.nframes - (total_frames + replicate_cnt_start))\n",
    "                frames_out = [frames[0]]*(replicate_cnt_start) + frames + [frames[-1]]*(replicate_cnt_end) \n",
    "            else: #total_frames == self.nframes\n",
    "                frames_out = frames\n",
    "                \n",
    "        else:#(self.nframes_selection_mode == \"dynamic-fps\"):\n",
    "            if(total_frames > self.nframes):\n",
    "                # delete frames at regular intervals until exactly nframes are left\n",
    "                if(self.debug):\n",
    "                    print(\"total_frames=\",total_frames,\"frames_excess=\",(total_frames - self.nframes))\n",
    "                frames_out = frames\n",
    "                delete_rate = (total_frames//(total_frames - self.nframes))\n",
    "                deleted = 0\n",
    "                i = 0 #start by first replicating the 0th frame\n",
    "                while(len(frames_out) > self.nframes):\n",
    "                    del_idx = i*delete_rate - deleted\n",
    "                    if(self.debug):\n",
    "                        print(\"removing frame at idx\",del_idx)\n",
    "                    del frames_out[del_idx]\n",
    "                    i += 1\n",
    "                    deleted += 1\n",
    "                \n",
    "            elif(total_frames < self.nframes):               \n",
    "                # duplicate frames at regular intervals until exactly nframes are left\n",
    "                if(self.debug):\n",
    "                    print(\"total_frames=\",total_frames,\"frames_shortage=\",(self.nframes - total_frames))\n",
    "                frames_out = frames\n",
    "                insert_rate = (total_frames//(self.nframes - total_frames))\n",
    "                inserted = 0\n",
    "                i = 0 #start by first replicating the 0th frame\n",
    "                while(len(frames_out) < self.nframes):\n",
    "                    dup_idx = i*insert_rate + inserted\n",
    "                    if(self.debug):\n",
    "                        print(\"duplicating frame at idx\",dup_idx)\n",
    "                    frames_out.insert(dup_idx, frames[dup_idx])\n",
    "                    i += 1\n",
    "                    inserted += 1\n",
    "                    \n",
    "            else: #total_frames == self.nframes\n",
    "                frames_out = frames      \n",
    "                \n",
    "#         print(len(frames), len(frames_out), [im.split(\"/\")[-1] for im in im_frames_out])\n",
    "#         # 'channels_first' or 'channels_last'?\n",
    "#         if(self.data_format == 'channels_last'):\n",
    "        X = np.empty(((self.nframes,) + target_im_size + (3,)), dtype=np.float32)\n",
    "#         else:\n",
    "#             X = np.empty((((3,) +  (self.nframes,) + self.im_shape)\n",
    "#                                , dtype=np.float32)\n",
    "            \n",
    "        for i,frame in enumerate(frames_out):\n",
    "            X[i] = self.load_img(frame, target_size=target_im_size)\n",
    "#             X[i] = img_to_array(load_img(frame, target_size=target_im_size)) \n",
    "        X = self.preprocess(X)\n",
    "    \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def load_img(self, img_dir, target_size):\n",
    "#       _PIL_INTERPOLATION_METHODS = {\n",
    "#         'nearest': pil_image.NEAREST,\n",
    "#         'bilinear': pil_image.BILINEAR,\n",
    "#         'bicubic': pil_image.BICUBIC,\n",
    "# }\n",
    "        im = pil_image.open(img_dir)\n",
    "        w, h = im.size\n",
    "        w_same_aspect =  int((target_size[0]/h)*w)\n",
    "        im = im.resize((target_size[0], w_same_aspect), pil_image.ANTIALIAS)\n",
    "\n",
    "        w_crop = (im.size[1] - target_size[1]) // 2\n",
    "        im = im.crop((0, w_crop, im.size[0], target_size[1]+w_crop))\n",
    "        im_arr = np.asarray(im, dtype=np.float32)\n",
    "        im_arr = np.moveaxis(im_arr, 0, 1)\n",
    "        return im_arr    \n",
    "    \n",
    "    \n",
    "    def preprocess(self, X):\n",
    "#         self.image_data_generator = ImageDataGenerator(\n",
    "#                                     featurewise_center=False\n",
    "#                                      , samplewise_center=False\n",
    "#                                      , featurewise_std_normalization=False\n",
    "#                                      , samplewise_std_normalization=False\n",
    "#                                      , zca_whitening=False\n",
    "#                                      , zca_epsilon=1e-06\n",
    "#                                      , rotation_range=0\n",
    "#                                      , width_shift_range=0.0\n",
    "#                                      , height_shift_range=0.0\n",
    "#                                      , brightness_range=None\n",
    "#                                      , shear_range=0.0\n",
    "#                                      , zoom_range=0.0\n",
    "#                                      , channel_shift_range=0.0\n",
    "#                                      , fill_mode='nearest'\n",
    "#                                      , cval=0.0\n",
    "#                                      , horizontal_flip=True\n",
    "#                                      , vertical_flip=False\n",
    "#                                      , rescale=1./255\n",
    "#                                      , preprocessing_function=None\n",
    "#                                      , data_format='channels_last'\n",
    "#                                      , validation_split=0.0\n",
    "#                                      , dtype='float32'\n",
    "#                                     )\n",
    "#         X = self.image_data_generator.standardize(X) # standardize to range [0,1]... preprocessing 3\n",
    "#         params = {'flip_horizontal':True}\n",
    "#         X = self.image_data_generator.apply_transform(X, params)\n",
    "        return X / 255\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x. # Returns  The next batch.\n",
    "        info : function taken directly from keras_preprocessing.DataFrameIterator class\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 48, 128, 224, 3)\n",
      "(8, 48, 128, 224, 3)\n",
      "(8, 48, 128, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "data_csv = pd.read_csv(\"/data/videos/something-something-v2/preprocessed/data.csv\")\n",
    "\n",
    "val_generator = SmthsmthGenerator(data_csv\n",
    "                                  , nframes=48\n",
    "                                  , split=\"val\"\n",
    "                                  , batch_size=8\n",
    "                                  , shuffle=True, seed=42\n",
    "                                  , reject_extremes = (24, 64)\n",
    "                                  , nframes_selection_mode = \"dynamic-fps\"\n",
    "                                 )\n",
    "len(val_generator)\n",
    "for i in range(3):\n",
    "    print(next(val_generator)[0].shape)\n",
    "# X_val = val_generator.create_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33 s ± 388 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "next(val_generator)[0].shape #todo speed up this shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6 s ± 269 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "next(val_generator)[1].shape #todo speed up this shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frames = next(val_generator)[0][0]\n",
    "for frm in frames:\n",
    "    print(frm.shape ,np.min(frm), np.mean(frm), np.max(frm))\n",
    "    plt.imshow(frm)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed_img_data_gen = ImageDataGenerator(data_format=data_format)\n",
    "#preprocessed_img_data_gen.fit(self.X)\n",
    "#model.fit_generator(preprocessed_img_data_gen.flow(x_train, y_train, batch_size=32),\n",
    "#             steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
    "# see dataset_smthsmth_analysis notebook for the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todos\n",
    "1. Is `smthsmthGenerator.create_all()` method required ? If yes, implement. (includes implementing `N_seq` argument.\n",
    "2. Analyse other preprocessing and data augumentations and implement the ones that might be necessary in `smthsmthGenerator.preprocess()` method  -> Not for now\n",
    "3. Try other PIL interpolation techniques in `smthsmthGenerator.load_img()` ?  -> Not for now\n",
    "4. Implement `output_mode == \"label\"` option which return the video action class label in `batch_y`. -> Edit ? For now return the label in str \n",
    "5. Implement 'channels_first' or 'channels_last' options ? -> Not for now\n",
    "6. Implement other `self.nframes_selection_mode`options  -> Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tar -zcvf smthsmth_data_utils.ipynb_backup1.tar.gz smthsmth_data_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
