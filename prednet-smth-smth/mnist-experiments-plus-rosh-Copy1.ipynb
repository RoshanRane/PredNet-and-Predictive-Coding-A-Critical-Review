{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras, keras_preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import LSTM, Lambda\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.models import load_model\n",
    "from keras.models import Model, model_from_json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from viz_utils import plot_loss_curves, plot_errors, plot_changes_in_r, return_difference\n",
    "from viz_utils import conditioned_ssim, sharpness_difference_grad, sharpness, sharpness_difference\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "plt.rcParams['figure.figsize'] = 30,15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz_utils import *\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old models folder\n",
    "suffix = \"1ss\" # set to \"\" for 4 numbers\n",
    "out_folder = \"moving_mnist_results_plus2\"\n",
    "seed = None\n",
    "# np.random.seed(seed)\n",
    "# tf.set_random_seed(seed)\n",
    "\n",
    "data_dict = {\n",
    "    \"weight_dir\" : os.path.join(os.getcwd(), out_folder),\n",
    "    \"result_dir\" : os.path.join(os.getcwd(), out_folder, \"results\"),\n",
    "    \"json_file\" : os.path.join(os.getcwd(), out_folder, \"model.json\"),\n",
    "    \"weights_file\": os.path.join(os.path.join(os.getcwd(), out_folder), 'prednet_mnist_weights.hdf5'),\n",
    "    \"json_file\": os.path.join(os.path.join(os.getcwd(), out_folder), 'prednet_mnist_model.json'),\n",
    "    \"nt\": 18,\n",
    "    \"datafile\" : \"../data/data{}.npy\".format(suffix),\n",
    "    \"datalabelsfile\" : \"../data/data{}_labels.npy\".format(suffix),\n",
    "    \"nval\" : 1000,\n",
    "    \"nb_epochs\" : 150,\n",
    "    \"batch_size\" : 32,\n",
    "    \"samples_per_epoch\" : None,\n",
    "    \"N_seq_val\" : None,\n",
    "    \"n_channels\" : 1,\n",
    "    \"im_height\" : 64,\n",
    "    \"im_width\" : 64,\n",
    "    \"n_chan_layer\" : [32, 64, 96, 128], #(1,32,64,128,256)\n",
    "    \"n_chan_R_layer\" : [],\n",
    "    \"layer_loss\" : [1., 0., 0., 0., 0.],\n",
    "    \"a_filt_sizes\": (3, 3, 3, 3),\n",
    "    \"ahat_filt_sizes\": (3, 3, 3, 3, 3),\n",
    "    \"r_filt_sizes\": (3, 3, 3, 3, 3),\n",
    "    \"lr\": 0.0003, # 0.001- 0.0008 - 0.0005 - 0.0001\n",
    "    \"lr_reduce_epoch\": 10,\n",
    "    \"multitask\": True,\n",
    "    \"std_param\": 0.5,\n",
    "    \"strided_conv_pool\": False,\n",
    "    \"nb_classes\" : 8,\n",
    "    \"n_chan_lbl_layer\" : [256],\n",
    "    \"second_loss_weight\":0.0005\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset ../data/data1ss.npy with shape=(10000, 20, 1, 64, 64)\n",
      "train split shape=(9000, 20, 64, 64, 1)\t val split shape=(1000, 20, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load moving numbers dataset\n",
    "data = np.load(data_dict[\"datafile\"]).astype(float) / 255\n",
    "labels = np.load(data_dict[\"datalabelsfile\"])\n",
    "print(\"loaded dataset {} with shape={}\".format(data_dict[\"datafile\"], data.shape))\n",
    "# move channel axis to the end and split into train and test\n",
    "data = np.moveaxis(data, 2, -1)\n",
    "\n",
    "_n = 0\n",
    "train_data = data[_n:-data_dict[\"nval\"],]\n",
    "val_data = data[-data_dict[\"nval\"]:,]\n",
    "train_label = labels[_n:-data_dict[\"nval\"]]\n",
    "val_label = labels[-data_dict[\"nval\"]:]\n",
    "assert train_data.shape[0] == train_label.shape[0]\n",
    "assert val_data.shape[0] == val_label.shape[0]\n",
    "\n",
    "n, nt, im_height, im_width, n_channels =  train_data.shape\n",
    "print(\"train split shape={}\\t val split shape={}\".format(train_data.shape, val_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformulate as a 8-class classification problem\n",
    "directions = [\"left\",\"top-left\",\"top\",\"top-right\",\n",
    "              \"right\",\"bot-right\",\"bot\",\"bot-left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3888x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 5 samples\n",
    "rand_idxs = np.random.randint(0, len(train_data), 1)\n",
    "\n",
    "n = data_dict[\"nt\"] if data_dict[\"nt\"]<=8 else 8 \n",
    "for i in rand_idxs:\n",
    "    x = train_data[i]\n",
    "    label = labels[i]\n",
    "        \n",
    "    f,axs = plt.subplots(1,n,figsize=(3*data_dict[\"nt\"],4))\n",
    "    for j in range(n):\n",
    "        axs[j].axis(\"off\")\n",
    "        axs[j].imshow(x[j].squeeze())\n",
    "        axs[j].set_title(directions[int(label[j,0,-1])], fontdict = {'fontsize' : 400//data_dict[\"nt\"]})\n",
    "        \n",
    "    plt.subplots_adjust(wspace=0.0001, hspace=0.0001)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prednet import PredNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weight directory if it does not exist\n",
    "if not os.path.exists(data_dict[\"weight_dir\"]):\n",
    "    os.makedirs(data_dict[\"weight_dir\"])\n",
    "    os.chmod(data_dict['weight_dir'], mode=0o777)\n",
    "    \n",
    "if not os.path.exists(data_dict[\"result_dir\"]):\n",
    "    os.makedirs(data_dict[\"result_dir\"])\n",
    "    os.chmod(data_dict['result_dir'], mode=0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels, im_height, im_width = (data_dict['n_channels'], data_dict['im_height'], data_dict['im_width'])\n",
    "input_shape = (n_channels, im_height, im_width) if K.image_data_format() == 'channels_first' else (\n",
    "        im_height, im_width, n_channels)\n",
    "stack_sizes = tuple([data_dict[\"n_channels\"]] + data_dict[\"n_chan_layer\"])\n",
    "if(len(data_dict[\"n_chan_R_layer\"]) != 0): \n",
    "    r_stack_sizes = tuple([data_dict[\"n_channels\"]] + data_dict[\"n_chan_R_layer\"])\n",
    "else:\n",
    "    r_stack_sizes = stack_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting for each layer in final loss; \"L_0\" model:  [1, 0, 0, 0], \"L_all\": [1, 0.1, 0.1, 0.1]\n",
    "# Checking if all the values in layer_loss are between 0.0 and 1.0\n",
    "# Checking if the length of all layer loss list is equal to the number of prednet layers\n",
    "assert all(1.0 >= i >= 0.0 for i in data_dict[\"layer_loss\"]) and len(data_dict[\"layer_loss\"]) == len(stack_sizes)\n",
    "layer_loss_weights = np.array(data_dict[\"layer_loss\"])\n",
    "layer_loss_weights = np.expand_dims(layer_loss_weights, 1)\n",
    "\n",
    "# equally weight all timesteps except the first\n",
    "time_steps = data_dict[\"nt\"]\n",
    "time_loss_weights = 1. / (time_steps - 1) * np.ones((time_steps, 1))\n",
    "time_loss_weights[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(time_steps,) + input_shape)\n",
    "nb_layers = len(data_dict['n_chan_layer'])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse_categorial_crossentropy_with_logits loss function for labels\n",
    "def CEloss(y_true, y_pred, n=data_dict['nt']):\n",
    "    loss = 0\n",
    "    for i in range(n):\n",
    "        loss += K.categorical_crossentropy(target=y_true[:,i], output=y_pred[:,i])\n",
    "    loss = (loss/n)*data_dict[\"second_loss_weight\"] # weighing the loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/rrane/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/users/rrane/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/users/rrane/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "if(data_dict['multitask']):\n",
    "        output_mode='error_and_label'\n",
    "        # Configuring the model\n",
    "        prednet = PredNet(stack_sizes, r_stack_sizes, data_dict[\"a_filt_sizes\"], data_dict[\"ahat_filt_sizes\"], \n",
    "                          data_dict[\"r_filt_sizes\"], return_sequences=True, output_mode=output_mode, \n",
    "                          strided_conv_pool=data_dict[\"strided_conv_pool\"], nb_classes=data_dict['nb_classes'],\n",
    "                          lbl_stack_sizes=data_dict['n_chan_lbl_layer']) \n",
    "        # errors will be (batch_size, nt, nb_layers), labels will be (batch_size, nt, num_classes)\n",
    "        errors_and_labels = prednet(inputs)\n",
    "        errors = Lambda(lambda x: x[:,:,:nb_layers], output_shape=(time_steps,nb_layers,))(errors_and_labels)\n",
    "        labels = Lambda(lambda x: x[:,:,nb_layers:], name='label', output_shape=(time_steps,data_dict['nb_classes']))(errors_and_labels)\n",
    "        \n",
    "        # calculate weighted error by layer\n",
    "        errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)],\n",
    "                                         trainable=False)(errors)\n",
    "        # will be (batch_size, nt)\n",
    "        errors_by_time = Flatten()(errors_by_time)  \n",
    "        # weight errors by time\n",
    "        final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False, name='y')(\n",
    "            errors_by_time) \n",
    "\n",
    "        # weighed sum of all label predictions over time\n",
    "#         labels = Lambda(lambda x: K.permute_dimensions(x,(0,2,1)))(labels)\n",
    "        # get_exp_t_weights() returns the weights that start at 0.0 and raise exponentially to 1.0 and plateau. \n",
    "        # Motivated by our prior belief that the model is allowed to slowly learn the right prediction class over time.\n",
    "#         time_label_weights = get_exp_t_weights(time_steps)\n",
    "        # weight labels by time      \n",
    "#         final_labels = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(\n",
    "#             labels)\n",
    "\n",
    "#         final_labels = Flatten(name='label')(final_labels)\n",
    "        # final_labels = labels\n",
    "        model = Model(inputs=inputs, outputs=([final_errors, labels]))\n",
    "        \n",
    "        model.compile(\n",
    "            loss={'y': 'mean_absolute_error', 'label':CEloss }\n",
    "            , optimizer='adam'\n",
    "            , metrics={'y': ['mse'], 'label': ['acc']}\n",
    "            )\n",
    "else:\n",
    "    output_mode='error'\n",
    "    prednet = PredNet(stack_sizes, r_stack_sizes,\n",
    "                      data_dict[\"a_filt_sizes\"], data_dict[\"ahat_filt_sizes\"], data_dict[\"r_filt_sizes\"],\n",
    "                      output_mode=output_mode, return_sequences=True)\n",
    "    errors = prednet(inputs)\n",
    "    \n",
    "    errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)], trainable=False)(errors)  # calculate weighted error by layer\n",
    "    errors_by_time = Flatten()(errors_by_time)  # will be (batch_size, nt)\n",
    "    final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(errors_by_time)  # weight errors by time\n",
    "    model = Model(inputs=inputs, outputs=final_errors)\n",
    "    model.compile(loss=data_dict['loss'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 18, 64, 64, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "pred_net_1 (PredNet)             (None, 18, 13)        7416794     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 18, 5)         0           pred_net_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 18, 1)         6           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18)            0           time_distributed_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "y (Dense)                        (None, 1)             19          flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "label (Lambda)                   (None, 18, 8)         0           pred_net_1[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 7,416,819\n",
      "Trainable params: 7,416,794\n",
      "Non-trainable params: 25\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Sequence generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator that creates sequences for input into PredNet.\n",
    "class SequenceGenerator(Iterator):\n",
    "    def __init__(self, data, nt, labels, data_dict, batch_size=8, shuffle=True, seed=None,\n",
    "                 output_mode='error', sequence_start_mode='all', N_seq=None, n_classes=10,\n",
    "                 data_format=K.image_data_format()):\n",
    "        self.X = data  # X will be like (n_images, nb_cols, nb_rows, nb_channels)\n",
    "        # self.sources = hkl.load(source_file) # source for each image so when creating sequences can assure that consecutive frames are from same video\n",
    "        self.nt = nt\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.n_classes = n_classes\n",
    "        self.data_format = data_format\n",
    "        assert sequence_start_mode in {'all', 'unique'}, 'sequence_start_mode must be in {all, unique}'\n",
    "        self.sequence_start_mode = sequence_start_mode\n",
    "        assert output_mode in {'error', 'prediction', 'label', 'error_and_label', 'prediction_and_label'}, 'output_mode must be in {error, prediction, label, error_and_label, prediction_and_label}'\n",
    "        self.output_mode = output_mode\n",
    "\n",
    "        if self.data_format == 'channels_first':\n",
    "            self.X = np.transpose(self.X, (0, 3, 1, 2))\n",
    "        self.im_shape = self.X[0][0].shape\n",
    "\n",
    "        if self.sequence_start_mode == 'all':  # allow for any possible sequence, starting from any frame\n",
    "            self.possible_starts = np.array(range(0, self.X.shape[1]-self.nt))\n",
    "\n",
    "        if shuffle:\n",
    "            self.possible_starts = np.random.permutation(self.possible_starts)\n",
    "        if N_seq is not None and len(self.possible_starts) > N_seq:  # select a subset of sequences if want to\n",
    "            self.possible_starts = self.possible_starts[:N_seq]\n",
    "        self.N_sequences = len(self.possible_starts)\n",
    "        super(SequenceGenerator, self).__init__(self.X.shape[0], batch_size, shuffle, seed)\n",
    "    \n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        batch_x = np.zeros((current_batch_size, self.nt) + self.im_shape, np.float32)\n",
    "        batch_label = np.zeros((current_batch_size, self.nt, self.n_classes), np.int32)\n",
    "        for i, idx in enumerate(index_array):\n",
    "            vid_idx = np.random.choice(self.possible_starts)\n",
    "            batch_x[i] = self.preprocess(self.X[idx, vid_idx:vid_idx+self.nt])\n",
    "            batch_label[i] = to_categorical(\n",
    "                self.labels[idx, vid_idx:vid_idx+self.nt, 0, -1].astype(int), self.n_classes)\n",
    "        if self.output_mode == 'error':  # model outputs errors, so y should be zeros\n",
    "            batch_y = np.zeros(current_batch_size, np.float32)\n",
    "        elif self.output_mode == 'prediction':  # output actual pixels\n",
    "            batch_y = batch_x\n",
    "        elif 'label' in self.output_mode:\n",
    "            # one_hot_encode the label\n",
    "            labels = batch_label\n",
    "            if self.output_mode == 'label':\n",
    "                batch_y = labels\n",
    "            elif self.output_mode == 'error_and_label':         \n",
    "                batch_y = {'y': np.zeros(current_batch_size, np.float32), 'label': labels}\n",
    "            elif self.output_mode == 'prediction_and_label':            \n",
    "                batch_y = {'y': batch_x, 'label': labels}\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        return X.astype(np.float32) / 255\n",
    "\n",
    "    def create_all(self):\n",
    "        X_all = np.zeros((self.N_sequences, self.nt) + self.im_shape, np.float32)\n",
    "        for i, idx in enumerate(self.possible_starts):\n",
    "            vid_idx = np.random.choice(self.possible_starts)\n",
    "            X_all[i] = self.preprocess(self.X[idx, vid_idx:vid_idx+self.nt])\n",
    "        return X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dict['multitask'] == True:\n",
    "    train_generator = SequenceGenerator(train_data, data_dict['nt'] , train_label, data_dict, batch_size=data_dict['batch_size'], output_mode='error_and_label', n_classes=data_dict[\"nb_classes\"], shuffle=True, seed=seed)\n",
    "    val_generator = SequenceGenerator(val_data, data_dict['nt'] , val_label, data_dict, batch_size=data_dict['batch_size'], output_mode='error_and_label', n_classes=data_dict[\"nb_classes\"], shuffle=False, seed=seed)\n",
    "else:\n",
    "    train_generator = SequenceGenerator(train_data, data_dict['nt'] ,None, data_dict, batch_size=data_dict['batch_size'], n_classes=data_dict[\"nb_classes\"], shuffle=True, seed=seed)\n",
    "    val_generator = SequenceGenerator(val_data, data_dict['nt'] ,None, data_dict, batch_size=data_dict['batch_size'], n_classes=data_dict[\"nb_classes\"], shuffle=False, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X=(32, 18, 64, 64, 1) \t Y=(32, 18, 8)\n",
      "Label [[0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the generator output\n",
    "X, Y = next(val_generator)\n",
    "print(\"shapes X={} \\t Y={}\".format(X.shape, Y['label'].shape))\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, sharex=True, figsize=(nt*2,2))\n",
    "# plot X[0]\n",
    "X = X[0,:,:,:,0]\n",
    "ax.imshow(np.concatenate([t for t in X[:,:,:]], axis=1), interpolation='none', aspect=\"auto\")\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labelleft=False)\n",
    "ax.set_ylabel(r'X[0]', fontsize=10)\n",
    "ax.set_xlim(0,time_steps*im_width)\n",
    "\n",
    "print(\"Label\",Y['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = lambda e : data_dict['lr']*(1 - 0.1*(e//data_dict['lr_reduce_epoch'])) if e//data_dict['lr_reduce_epoch']<10 else 0.1*data_dict['lr']\n",
    "callbacks = [LearningRateScheduler(lr_schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dict['weight_dir']): \n",
    "    os.mkdir(data_dict['weight_dir'])\n",
    "    os.chmod(data_dict['weight_dir'], mode=0o777)\n",
    "callbacks.append(ModelCheckpoint(filepath=data_dict['weights_file'], monitor='val_loss', save_best_only=True))\n",
    "callbacks.append(EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=25, verbose=1,\n",
    "                      mode='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dict['json_file'], \"w\") as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = data_dict['samples_per_epoch']//data_dict['batch_size'] if data_dict['samples_per_epoch'] is not None else train_generator.n//data_dict['batch_size']\n",
    "validation_steps = int(data_dict['N_seq_val']/data_dict['batch_size']) if  data_dict['N_seq_val'] is not None else val_generator.n//data_dict['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "281/281 [==============================] - 297s - loss: 0.0012 - y_loss: 1.8362e-04 - label_loss: 0.0010 - y_mean_squared_error: 4.2777e-08 - label_acc: 0.1290 - val_loss: 0.0012 - val_y_loss: 1.1694e-04 - val_label_loss: 0.0010 - val_y_mean_squared_error: 1.4093e-08 - val_label_acc: 0.1193\n",
      "Epoch 2/150\n",
      "281/281 [==============================] - 286s - loss: 0.0011 - y_loss: 1.0505e-04 - label_loss: 0.0010 - y_mean_squared_error: 1.1407e-08 - label_acc: 0.1308 - val_loss: 0.0011 - val_y_loss: 1.0402e-04 - val_label_loss: 0.0010 - val_y_mean_squared_error: 1.1131e-08 - val_label_acc: 0.1195\n",
      "Epoch 3/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 9.0309e-05 - label_loss: 0.0010 - y_mean_squared_error: 8.4414e-09 - label_acc: 0.1300 - val_loss: 0.0011 - val_y_loss: 8.6547e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 7.7459e-09 - val_label_acc: 0.1201\n",
      "Epoch 4/150\n",
      "281/281 [==============================] - 286s - loss: 0.0011 - y_loss: 7.9766e-05 - label_loss: 0.0010 - y_mean_squared_error: 6.5993e-09 - label_acc: 0.1308 - val_loss: 0.0011 - val_y_loss: 8.4175e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 7.3182e-09 - val_label_acc: 0.1201\n",
      "Epoch 5/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 7.2788e-05 - label_loss: 0.0010 - y_mean_squared_error: 5.5122e-09 - label_acc: 0.1302 - val_loss: 0.0011 - val_y_loss: 7.0165e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 5.1182e-09 - val_label_acc: 0.1213\n",
      "Epoch 6/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 6.8408e-05 - label_loss: 0.0010 - y_mean_squared_error: 4.8794e-09 - label_acc: 0.1302 - val_loss: 0.0011 - val_y_loss: 6.5210e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 4.4367e-09 - val_label_acc: 0.1175\n",
      "Epoch 7/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 6.3571e-05 - label_loss: 0.0010 - y_mean_squared_error: 4.2338e-09 - label_acc: 0.1315 - val_loss: 0.0011 - val_y_loss: 6.0579e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 3.8435e-09 - val_label_acc: 0.1206\n",
      "Epoch 8/150\n",
      "281/281 [==============================] - 285s - loss: 0.0011 - y_loss: 6.0340e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.8219e-09 - label_acc: 0.1306 - val_loss: 0.0011 - val_y_loss: 6.3270e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 4.1718e-09 - val_label_acc: 0.1192\n",
      "Epoch 9/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 5.7153e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.4449e-09 - label_acc: 0.1307 - val_loss: 0.0011 - val_y_loss: 5.6724e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 3.3874e-09 - val_label_acc: 0.1198\n",
      "Epoch 10/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 5.7100e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.4503e-09 - label_acc: 0.1323 - val_loss: 0.0011 - val_y_loss: 5.3947e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 3.0751e-09 - val_label_acc: 0.1185\n",
      "Epoch 11/150\n",
      "281/281 [==============================] - 286s - loss: 0.0011 - y_loss: 5.3832e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.0711e-09 - label_acc: 0.1294 - val_loss: 0.0011 - val_y_loss: 5.2704e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.9387e-09 - val_label_acc: 0.1173\n",
      "Epoch 12/150\n",
      "281/281 [==============================] - 286s - loss: 0.0011 - y_loss: 5.2474e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.9196e-09 - label_acc: 0.1305 - val_loss: 0.0011 - val_y_loss: 5.1880e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.8544e-09 - val_label_acc: 0.1207\n",
      "Epoch 13/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 5.1876e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.8609e-09 - label_acc: 0.1302 - val_loss: 0.0011 - val_y_loss: 5.1100e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.7782e-09 - val_label_acc: 0.1221\n",
      "Epoch 14/150\n",
      "281/281 [==============================] - 286s - loss: 0.0011 - y_loss: 5.4654e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.2716e-09 - label_acc: 0.1314 - val_loss: 0.0011 - val_y_loss: 5.3714e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 3.0564e-09 - val_label_acc: 0.1171\n",
      "Epoch 15/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 5.0289e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.6945e-09 - label_acc: 0.1292 - val_loss: 0.0011 - val_y_loss: 4.9482e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.6070e-09 - val_label_acc: 0.1220\n",
      "Epoch 16/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 4.9785e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.6506e-09 - label_acc: 0.1320 - val_loss: 0.0011 - val_y_loss: 4.8576e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.5162e-09 - val_label_acc: 0.1206\n",
      "Epoch 17/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 4.8285e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.4984e-09 - label_acc: 0.1311 - val_loss: 0.0011 - val_y_loss: 4.7679e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.4268e-09 - val_label_acc: 0.1193\n",
      "Epoch 18/150\n",
      "281/281 [==============================] - 286s - loss: 0.0011 - y_loss: 4.9544e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.6400e-09 - label_acc: 0.1298 - val_loss: 0.0011 - val_y_loss: 4.7716e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.4357e-09 - val_label_acc: 0.1196\n",
      "Epoch 19/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 4.6700e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.3451e-09 - label_acc: 0.1307 - val_loss: 0.0011 - val_y_loss: 4.5921e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.2629e-09 - val_label_acc: 0.1213\n",
      "Epoch 20/150\n",
      "281/281 [==============================] - 287s - loss: 0.0011 - y_loss: 4.5875e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.2698e-09 - label_acc: 0.1310 - val_loss: 0.0011 - val_y_loss: 4.5699e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.2405e-09 - val_label_acc: 0.1187\n",
      "Epoch 21/150\n",
      "281/281 [==============================] - 286s - loss: 0.0011 - y_loss: 4.5129e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.2007e-09 - label_acc: 0.1315 - val_loss: 0.0011 - val_y_loss: 4.4816e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.1603e-09 - val_label_acc: 0.1187\n",
      "Epoch 22/150\n",
      "281/281 [==============================] - 286s - loss: 0.0011 - y_loss: 4.4799e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.1679e-09 - label_acc: 0.1295 - val_loss: 0.0011 - val_y_loss: 4.4284e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.1112e-09 - val_label_acc: 0.1217\n",
      "Epoch 23/150\n",
      "281/281 [==============================] - 286s - loss: 0.0011 - y_loss: 4.4290e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.1208e-09 - label_acc: 0.1308 - val_loss: 0.0011 - val_y_loss: 4.4923e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.1687e-09 - val_label_acc: 0.1188\n",
      "Epoch 24/150\n",
      "218/281 [======================>.......] - ETA: 62s - loss: 0.0011 - y_loss: 4.4194e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.1083e-09 - label_acc: 0.1304"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=data_dict['nb_epochs'],\n",
    "                              callbacks=callbacks, \n",
    "                              validation_data=val_generator, \n",
    "                              validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training history to a file\n",
    "with open(os.path.join(data_dict['result_dir'], 'training_history.json'), 'w') as f:\n",
    "    json.dump(history.history, f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading best model\n",
    "# data_dict['json_file'] = os.path.join(os.path.join(os.getcwd(), \"mnist_best_prednet\"), 'prednet_mnist_model.json')\n",
    "# data_dict['weights_file'] = os.path.join(os.path.join(os.getcwd(), \"mnist_best_prednet\"), 'prednet_mnist_weights.hdf5')\n",
    "\n",
    "# Loading trained model\n",
    "with open(data_dict['json_file'], 'r') as f:\n",
    "    json_string = f.read()\n",
    "\n",
    "model = model_from_json(json_string, custom_objects={'PredNet': PredNet, 'nb_layers':nb_layers})\n",
    "model.load_weights(data_dict['weights_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing model (to output predictions)\n",
    "layer_config = model.layers[1].get_config()\n",
    "if(data_dict[\"multitask\"]):\n",
    "    output_mode = 'prediction_and_label' \n",
    "else:\n",
    "    output_mode = 'prediction'\n",
    "layer_config['output_mode'] = output_mode\n",
    "data_format = layer_config['data_format'] if 'data_format' in layer_config else layer_config['dim_ordering']\n",
    "test_prednet = PredNet(weights=model.layers[1].get_weights(), **layer_config)\n",
    "input_shape = list(model.layers[0].batch_input_shape[1:])\n",
    "input_shape[0] = time_steps\n",
    "inputs = Input(shape=tuple(input_shape))\n",
    "predictions = test_prednet(inputs)\n",
    "test_model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #initialize lists for evaluation        \n",
    "mse_model_list, mse_prev_list, mae_model_list, mae_prev_list = ([] for i in range(4))\n",
    "psnr_list, ssim_list, sharpness_grad_list, psnr_prev_list, ssim_prev_list, sharpness_grad_prev_list = ([] for i in range(6))\n",
    "psnr_movement_list, psnr_movement_prev_list, ssim_movement_list, ssim_movement_prev_list =  ([] for i in range(4))\n",
    "conditioned_ssim_list, sharpness_list, sharpness_prev_list = ([] for i in range(3))\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO:  adhoc to speed things up \n",
    "data_dict['batch_size'] = 128\n",
    "max_test_batches = val_generator.n // 128 # adhoc, only run on few batches (/8)\n",
    "\n",
    "for index, data in enumerate(val_generator):\n",
    "    # Only consider steps_test number of steps\n",
    "    if index > max_test_batches:\n",
    "        break\n",
    "    # X_test = test_generator.next()[0]\n",
    "    X_test = data[0]        \n",
    "\n",
    "    if(data_dict['multitask']==True):\n",
    "        lbl = data[1]['label']\n",
    "        lbl_final = lbl.argmax(axis=-1)\n",
    "        X_hat_with_lbl = test_model.predict(X_test, data_dict['batch_size'])\n",
    "        X_hat, lbl_hat = X_hat_with_lbl[:,:,:-data_dict[\"nb_classes\"]], X_hat_with_lbl[:,:,-data_dict[\"nb_classes\"]:]\n",
    "        # print(\"<d>\", lbl_hat.shape, lbl_hat.max(), lbl_hat.min(), lbl_hat.mean())\n",
    "        X_hat  = np.reshape(X_hat, X_test.shape) \n",
    "#         lbl_pred_final_logits = np.moveaxis(lbl_hat,1,2).dot(get_exp_t_weights(time_steps)).squeeze()\n",
    "        lbl_pred_final = lbl_hat.argmax(axis=-1)\n",
    "        if index==0: \n",
    "            # visualize the predicted labels for the first round\n",
    "            for i in range(-data_dict['nt']-3,-data_dict['nt']):\n",
    "                print(\"\\nExpected labels  = \\n\", [directions[l] for l in lbl_final[i]]) \n",
    "                print(\"Predicted labels = \\n\", [directions[l] for l in lbl_pred_final[i]])\n",
    "        acc = (lbl_pred_final == lbl_final).mean()\n",
    "        print(\"{}, accuracy= {:.2f}%\".format(index, acc*100))\n",
    "        accuracy_list.append(acc)\n",
    "    else:\n",
    "        X_hat = test_model.predict(X_test, data_dict['batch_size'])\n",
    "    if data_format == 'channels_first':\n",
    "        X_test = np.transpose(X_test, (0, 1, 3, 4, 2))\n",
    "        X_hat = np.transpose(X_hat, (0, 1, 3, 4, 2))\n",
    "\n",
    "    # Compare the scores of PredNet predictions vs. using last frame.  Write results to prediction_scores.txt\n",
    "    # mean square error\n",
    "    mse_model_list.append(\n",
    "        np.mean((X_test[:, 1:] - X_hat[:, 1:]) ** 2))  # look at all timesteps except the first\n",
    "    mse_prev_list.append(np.mean((X_test[:, :-1] - X_test[:, 1:]) ** 2))\n",
    "    # mean absolute error\n",
    "    mae_model_list.append(\n",
    "        np.mean(np.abs(X_test[:, 1:] - X_hat[:, 1:])))\n",
    "    mae_prev_list.append(np.mean(np.abs(X_test[:, :-1] - X_test[:, 1:])))\n",
    "    # ssim\n",
    "    ssim_list.append(np.mean([return_difference(X_test[ind][1:], X_hat[ind][1:])[0] for ind in range(X_test.shape[0])]))\n",
    "    ssim_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[0] \n",
    "                                   for ind in range(X_test.shape[0]-1)]))\n",
    "    ssim_movement_list.append(np.mean([return_difference(X_test[ind], X_hat[ind])[2] \n",
    "                                       for ind in range(X_test.shape[0])]))\n",
    "    ssim_movement_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[2] \n",
    "                                   for ind in range(X_test.shape[0]-1)])) \n",
    "    conditioned_ssim_list.append(np.mean([conditioned_ssim(X_test[ind], X_hat[ind]) \n",
    "                                   for ind in range(X_test.shape[0])])) \n",
    "\n",
    "    # psnr\n",
    "    psnr_list.append(np.mean([return_difference(X_test[ind][1:], X_hat[ind][1:])[1] for ind in range(X_test.shape[0])]))            \n",
    "    psnr_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[1] \n",
    "                                   for ind in range(X_test.shape[0]-1)]))\n",
    "    psnr_movement_list.append(np.mean([return_difference(X_test[ind], X_hat[ind])[3] \n",
    "                                       for ind in range(X_test.shape[0])]))\n",
    "    psnr_movement_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[3] \n",
    "                                   for ind in range(X_test.shape[0]-1)]))\n",
    "\n",
    "    # sharpness\n",
    "#     sharpness_grad_list.append(np.mean([sharpness_difference_grad(X_test[ind][1:], X_hat[ind][1:])\n",
    "#                                    for ind in range(X_test.shape[0])]))\n",
    "    #sharpness_grad_prev_list.append(np.mean([sharpness_difference_grad(X_test[ind][:-1], X_test[ind][1:])\n",
    "    #                                    for ind in range(X_test.shape[0]-1)]))\n",
    "\n",
    "#     sharpness_list.append(np.mean([sharpness_difference(X_test[ind][1:], X_hat[ind][1:])\n",
    "#                                   for ind in range(X_test.shape[0])]))\n",
    "    #sharpness_prev_list.append(np.mean([sharpness_difference(X_test[ind][:-1], X_test[ind][1:])\n",
    "    #                               for ind in range(X_test.shape[0])]))\n",
    "\n",
    "    \n",
    "# save in a dict and limit the size of float decimals to max 6\n",
    "results_dict = {                    \n",
    "\"MSE_mean\": float(\"{:.10f}\".format(np.mean(mse_model_list))), \n",
    "\"MSE_std\":float((\"{:.10f}\".format(np.std(mse_model_list)))), \n",
    "\"MSE_mean_prev_frame_copy\":float(\"{:.10f}\".format(np.mean(mse_prev_list))), \n",
    "\"MSE_std_prev_frame_copy\":float(\"{:.10f}\".format(np.std(mse_prev_list))),\n",
    "\"MAE_mean\": float(\"{:.6f}\".format(np.mean(mae_model_list))), \n",
    "\"MAE_std\":float((\"{:.6f}\".format(np.std(mae_model_list)))), \n",
    "\"MAE_mean_prev_frame_copy\":float(\"{:.6f}\".format(np.mean(mae_prev_list))), \n",
    "\"MAE_std_prev_frame_copy\":float(\"{:.6f}\".format(np.std(mae_prev_list))),\n",
    "\"SSIM_mean\": float(\"{:.6f}\".format(np.mean(ssim_list))), \n",
    "\"SSIM_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(ssim_prev_list))), \n",
    "\"SSIM_movement_mean\": float(\"{:.6f}\".format(np.mean(ssim_movement_list))), \n",
    "\"SSIM_movement_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(ssim_movement_prev_list))), \n",
    "\"Conditioned_SSIM_mean\": float(\"{:.6f}\".format(np.mean(conditioned_ssim_list))),\n",
    "\"PSNR_mean\": float(\"{:.6f}\".format(np.mean(psnr_list))),\n",
    "\"PSNR_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(psnr_prev_list))), \n",
    "\"PSNR_movement_mean\": float(\"{:.6f}\".format(np.mean(psnr_movement_list))), \n",
    "\"PSNR_movement_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(psnr_movement_prev_list))), \n",
    "\"Sharpness_grad_mean\": float(\"{:.6f}\".format(np.mean(sharpness_grad_list))),\n",
    "#\"Sharpness_grad_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(sharpness_grad_prev_list))),\n",
    "\"Sharpness_difference_mean\": float(\"{:.6f}\".format(np.mean(sharpness_list)))\n",
    "#\"Sharpness_difference_mean_prev_frame_copy\" : float(\"{:.6f}\".format(np.mean(sharpness_prev_list)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model results for training dataset:\")\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['MSE_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dict['result_dir'], 'mnist_scores.json'), 'w') as f:\n",
    "    json.dump(results_dict, f, sort_keys=True,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating extra plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_plot_flag = False\n",
    "\n",
    "plot_save_dir = os.path.join(data_dict['result_dir'], 'predictions')\n",
    "if not os.path.exists(plot_save_dir):\n",
    "    os.makedirs(plot_save_dir)\n",
    "\n",
    "assert X_test.shape==X_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extra_plot_flag:\n",
    "    #Create models for error and R plots\n",
    "    extra_test_models = []\n",
    "    no_layers = len(test_prednet.stack_sizes)\n",
    "    extra_output_modes = (['E'+str(no) for no in range(no_layers)] + ['A'+str(no) for no in range(no_layers)] \n",
    "                        + ['Ahat'+str(no) for no in range(no_layers)] + ['R'+str(no) for no in range(no_layers)])\n",
    "\n",
    "    for output_mode in extra_output_modes:\n",
    "        if(data_dict['multitask'] == True):\n",
    "            output_mode += \"_and_label\"\n",
    "        layer_config['output_mode'] = output_mode    \n",
    "        data_format = (layer_config['data_format'] if 'data_format' in layer_config \n",
    "                        else layer_config['dim_ordering'])\n",
    "        extra_test_prednet = PredNet(weights=model.layers[1].get_weights(), **layer_config)\n",
    "        input_shape = list(model.layers[0].batch_input_shape[1:])\n",
    "        input_shape[0] = data_dict['nt']\n",
    "        inputs = Input(shape=tuple(input_shape))\n",
    "        extra_predictions = extra_test_prednet(inputs)\n",
    "        extra_test_model = Model(inputs=inputs, outputs=extra_predictions)\n",
    "        extra_test_models.append((extra_test_model, output_mode))\n",
    "    \n",
    "    #Create outputs for extra plots\n",
    "    error_X_hats = []\n",
    "    R_X_hats = []\n",
    "    A_X_hats = []\n",
    "    Ahat_X_hats = []\n",
    "    for test_model, output_mode in extra_test_models:\n",
    "        if output_mode[0]=='R':\n",
    "            R_X_hat = test_model.predict(X_test) \n",
    "            R_X_hats.append((R_X_hat, output_mode))\n",
    "        elif output_mode[0]=='E':\n",
    "            error_X_hat = test_model.predict(X_test) \n",
    "            error_X_hats.append((error_X_hat, output_mode))\n",
    "        elif 'Ahat' in output_mode: \n",
    "            Ahat_X_hat = test_model.predict(X_test) \n",
    "            Ahat_X_hats.append((Ahat_X_hat, output_mode))\n",
    "        else: # output_mode[0]=='A':\n",
    "            A_X_hat = test_model.predict(X_test) \n",
    "            A_X_hats.append((A_X_hat, output_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample 'plots_per_grp' videos from each sub-group\n",
    "aspect_ratio = float(X_hat.shape[2]) / X_hat.shape[3]\n",
    "for i in range(3):      #len(X_test)    \n",
    "    if extra_plot_flag:\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=20, sharex=True, figsize=(time_steps, 25 * aspect_ratio),\n",
    "                              gridspec_kw={'height_ratios':[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,3,3]})\n",
    "    else:\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=2, sharex=True, figsize=(time_steps, 2 * aspect_ratio))\n",
    "\n",
    "    # set the title of the plot as the label and the video ID for reference\n",
    "    if(data_dict['multitask']):\n",
    "        title = \"{}) TRUE {}\\n PRED: {}\".format(\n",
    "        i, \n",
    "        [directions[lbl] for lbl in lbl_final[i]],\n",
    "        [directions[lbl] for lbl in lbl_pred_final[i]])\n",
    "    else:\n",
    "        title = \"{}) Digit {}\".format( # Pos {}\n",
    "        i, \n",
    "        np.unique(val_label[i,0,:,0].astype(int))\n",
    "#         ,val_label[i,:,0,1:]\n",
    ")\n",
    "\n",
    "    fig.suptitle(title, fontsize=10)\n",
    "\n",
    "    #Plot video\n",
    "    ax = plt.subplot()\n",
    "    ax.imshow(np.concatenate([t for t in X_test[i,:,:,:,0]], axis=1), interpolation='none', aspect=\"auto\")\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False,\n",
    "                                    labelbottom=False, labelleft=False)\n",
    "    ax.set_ylabel(r'Actual', fontsize=10)\n",
    "    ax.set_xlim(0,time_steps*im_width)\n",
    "\n",
    "    #Plot predictions\n",
    "    divider = make_axes_locatable(ax)\n",
    "    ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                             \n",
    "    ax.imshow(np.concatenate([t for t in X_hat[i,:,:,:,0]], axis=1), interpolation='none', aspect=\"auto\")\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False,\n",
    "                                    labelbottom=False, labelleft=False)\n",
    "    ax.set_ylabel(r'Prediction', fontsize=10)\n",
    "    ax.set_xlim(0,time_steps*im_width)\n",
    "    \n",
    "    if extra_plot_flag:\n",
    "        #Create values for R plots      \n",
    "        results = plot_changes_in_r(R_X_hats, i, std_param=data_dict['std_param'])\n",
    "        ax = divider.append_axes(\"bottom\", size=\"300%\", pad=0.2)                                                                \n",
    "        #Plot R plots\n",
    "        for layer in results:\n",
    "            (y,x,std) = layer[0]\n",
    "            x = [im_width/2+item*im_width for item in x]\n",
    "            ax.fill_between(x, [(val-data_dict['std_param']*dev) for val,dev in zip(y,std)], \n",
    "                             [(val+data_dict['std_param']*dev) for val,dev in zip(y,std)], alpha=0.1)\n",
    "            ax.plot(x, y)\n",
    "\n",
    "        ax.set_xlim(0,time_steps*im_width)\n",
    "        ax.set_xticks(np.arange(im_width/2, time_steps*im_width, step=im_width))                \n",
    "        ax.set_xticklabels(np.arange(1,time_steps+1))\n",
    "        ax.grid(True)                  \n",
    "        ax.set_ylabel(r\"Mean R activations\", fontsize=10)\n",
    "        ax.xaxis.set_label_position('top') \n",
    "        ax.legend(['R'+str(no) for no in range(no_layers)], loc='center left')\n",
    "\n",
    "        #Create values for E plots      \n",
    "        results = plot_changes_in_r(error_X_hats, i, std_param=data_dict['std_param'])\n",
    "        ax = divider.append_axes(\"bottom\", size=\"300%\", pad=0.2)                                                                \n",
    "        #Plot E plots\n",
    "        for layer in results:\n",
    "            (y,x,std) = layer[0]\n",
    "            x = [im_width/2+item*im_width for item in x]\n",
    "            ax.fill_between(x, [(val-data_dict['std_param']*dev) for val,dev in zip(y,std)], \n",
    "                            [(val+data_dict['std_param']*dev) for val,dev in zip(y,std)], alpha=0.1)\n",
    "            ax.plot(x, y)\n",
    "\n",
    "        ax.set_xlim(0,time_steps*im_width)\n",
    "        ax.set_xticks(np.arange(im_width/2, time_steps*im_width, step=im_width))                \n",
    "        ax.set_xticklabels(np.arange(1,time_steps+1))\n",
    "        ax.grid(True)                  \n",
    "        ax.set_ylabel(r\"Mean E activations\", fontsize=10)\n",
    "        ax.xaxis.set_label_position('top') \n",
    "        ax.legend(['E'+str(no) for no in range(no_layers)], loc='center left')\n",
    "\n",
    "        #Create error output matrices to plot inside the next loop\n",
    "        R_matrices = plot_errors(R_X_hats, X_test, ind=i)\n",
    "        A_matrices =  plot_errors(A_X_hats, X_test, ind=i) \n",
    "        Ahat_matrices = plot_errors(Ahat_X_hats, X_test, ind=i)\n",
    "        error_matrices = plot_errors(error_X_hats, X_test, ind=i)\n",
    "        #Plot R, A, Ahat and errors for each layer\n",
    "        for layer in range(len(error_matrices)):   \n",
    "                ##R\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.2)                                             \n",
    "                ax.imshow(np.concatenate([t for t in R_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"R\" + str(layer), fontsize=10)\n",
    "                ax.set_xlabel(r\"Layer \" + str(layer), fontsize=10)\n",
    "                ax.xaxis.set_label_position('top') \n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "                ##A\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                             \n",
    "                ax.imshow(np.concatenate([t for t in Ahat_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"Ahat\" + str(layer), fontsize=10)\n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "                ##Ahat\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                     \n",
    "                ax.imshow(np.concatenate([t for t in A_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"A\" + str(layer), fontsize=10)\n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "                ##E\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                             \n",
    "                ax.imshow(np.concatenate([t for t in error_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"E\" + str(layer), fontsize=10)\n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(plot_save_dir+\"/\"+\"prediction\"+str(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
