{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras, keras_preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import LSTM, Lambda\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.models import load_model\n",
    "from keras.models import Model, model_from_json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from viz_utils import plot_loss_curves, plot_errors, plot_changes_in_r, return_difference\n",
    "from viz_utils import conditioned_ssim, sharpness_difference_grad, sharpness, sharpness_difference\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "plt.rcParams['figure.figsize'] = 30,15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz_utils import *\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old models folder\n",
    "suffix = \"1ss\" # set to \"\" for 4 numbers\n",
    "out_folder = \"moving_mnist_results_plus\"\n",
    "seed = None\n",
    "# np.random.seed(seed)\n",
    "# tf.set_random_seed(seed)\n",
    "\n",
    "data_dict = {\n",
    "    \"weight_dir\" : os.path.join(os.getcwd(), out_folder),\n",
    "    \"result_dir\" : os.path.join(os.getcwd(), out_folder, \"results\"),\n",
    "    \"json_file\" : os.path.join(os.getcwd(), out_folder, \"model.json\"),\n",
    "    \"save_model\": True,\n",
    "    \"weights_file\": os.path.join(os.path.join(os.getcwd(), out_folder), 'prednet_mnist_weights.hdf5'),\n",
    "    \"json_file\": os.path.join(os.path.join(os.getcwd(), out_folder), 'prednet_mnist_model.json'),\n",
    "    \"nt\": 18,\n",
    "    \"datafile\" : \"../data/data{}.npy\".format(suffix),\n",
    "    \"datalabelsfile\" : \"../data/data{}_labels.npy\".format(suffix),\n",
    "    \"nval\" : 1000,\n",
    "    \"nb_epochs\" : 150,\n",
    "    \"batch_size\" : 32,\n",
    "    \"samples_per_epoch\" : None,\n",
    "    \"N_seq_val\" : None,\n",
    "    \"n_channels\" : 1,\n",
    "    \"im_height\" : 64,\n",
    "    \"im_width\" : 64,\n",
    "    \"n_chan_layer\" : [32, 64, 96, 128], #(1,32,64,128,256)\n",
    "    \"n_chan_R_layer\" : [],\n",
    "    \"layer_loss\" : [1., 0., 0., 0., 0.],\n",
    "    \"a_filt_sizes\": (3, 3, 3, 3),\n",
    "    \"ahat_filt_sizes\": (3, 3, 3, 3, 3),\n",
    "    \"r_filt_sizes\": (3, 3, 3, 3, 3),\n",
    "    \"lr\": 0.0003, # 0.001- 0.0008 - 0.0005 - 0.0001\n",
    "    \"lr_reduce_epoch\": 10,\n",
    "    \"multitask\": True,\n",
    "    \"std_param\": 0.5,\n",
    "    \"strided_conv_pool\": False,\n",
    "    \"nb_classes\" : 8,\n",
    "    \"n_chan_lbl_layer\" : [128],\n",
    "    \"second_loss_weight\":0.0005\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset ../data/data1ss.npy with shape=(10000, 20, 1, 64, 64)\n",
      "train split shape=(9000, 20, 64, 64, 1)\t val split shape=(1000, 20, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load moving numbers dataset\n",
    "data = np.load(data_dict[\"datafile\"]).astype(float) / 255\n",
    "labels = np.load(data_dict[\"datalabelsfile\"])\n",
    "print(\"loaded dataset {} with shape={}\".format(data_dict[\"datafile\"], data.shape))\n",
    "# move channel axis to the end and split into train and test\n",
    "data = np.moveaxis(data, 2, -1)\n",
    "\n",
    "_n = 0\n",
    "train_data = data[_n:-data_dict[\"nval\"],]\n",
    "val_data = data[-data_dict[\"nval\"]:,]\n",
    "train_label = labels[_n:-data_dict[\"nval\"]]\n",
    "val_label = labels[-data_dict[\"nval\"]:]\n",
    "assert train_data.shape[0] == train_label.shape[0]\n",
    "assert val_data.shape[0] == val_label.shape[0]\n",
    "\n",
    "n, nt, im_height, im_width, n_channels =  train_data.shape\n",
    "print(\"train split shape={}\\t val split shape={}\".format(train_data.shape, val_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformulate as a 8-class classification problem\n",
    "directions = [\"left\",\"top-left\",\"top\",\"top-right\",\n",
    "              \"right\",\"bot-right\",\"bot\",\"bot-left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3888x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 5 samples\n",
    "rand_idxs = np.random.randint(0, len(train_data), 1)\n",
    "\n",
    "n = data_dict[\"nt\"] if data_dict[\"nt\"]<=8 else 8 \n",
    "for i in rand_idxs:\n",
    "    x = train_data[i]\n",
    "    label = labels[i]\n",
    "        \n",
    "    f,axs = plt.subplots(1,n,figsize=(3*data_dict[\"nt\"],4))\n",
    "    for j in range(n):\n",
    "        axs[j].axis(\"off\")\n",
    "        axs[j].imshow(x[j].squeeze())\n",
    "        axs[j].set_title(directions[int(label[j,0,-1])], fontdict = {'fontsize' : 400//data_dict[\"nt\"]})\n",
    "        \n",
    "    plt.subplots_adjust(wspace=0.0001, hspace=0.0001)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prednet import PredNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weight directory if it does not exist\n",
    "if not os.path.exists(data_dict[\"weight_dir\"]):\n",
    "    os.makedirs(data_dict[\"weight_dir\"])\n",
    "    os.chmod(data_dict['weight_dir'], mode=0o777)\n",
    "    \n",
    "if not os.path.exists(data_dict[\"result_dir\"]):\n",
    "    os.makedirs(data_dict[\"result_dir\"])\n",
    "    os.chmod(data_dict['result_dir'], mode=0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels, im_height, im_width = (data_dict['n_channels'], data_dict['im_height'], data_dict['im_width'])\n",
    "input_shape = (n_channels, im_height, im_width) if K.image_data_format() == 'channels_first' else (\n",
    "        im_height, im_width, n_channels)\n",
    "stack_sizes = tuple([data_dict[\"n_channels\"]] + data_dict[\"n_chan_layer\"])\n",
    "if(len(data_dict[\"n_chan_R_layer\"]) != 0): \n",
    "    r_stack_sizes = tuple([data_dict[\"n_channels\"]] + data_dict[\"n_chan_R_layer\"])\n",
    "else:\n",
    "    r_stack_sizes = stack_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting for each layer in final loss; \"L_0\" model:  [1, 0, 0, 0], \"L_all\": [1, 0.1, 0.1, 0.1]\n",
    "# Checking if all the values in layer_loss are between 0.0 and 1.0\n",
    "# Checking if the length of all layer loss list is equal to the number of prednet layers\n",
    "assert all(1.0 >= i >= 0.0 for i in data_dict[\"layer_loss\"]) and len(data_dict[\"layer_loss\"]) == len(stack_sizes)\n",
    "layer_loss_weights = np.array(data_dict[\"layer_loss\"])\n",
    "layer_loss_weights = np.expand_dims(layer_loss_weights, 1)\n",
    "\n",
    "# equally weight all timesteps except the first\n",
    "time_steps = data_dict[\"nt\"]\n",
    "time_loss_weights = 1. / (time_steps - 1) * np.ones((time_steps, 1))\n",
    "time_loss_weights[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(time_steps,) + input_shape)\n",
    "nb_layers = len(data_dict['n_chan_layer'])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse_categorial_crossentropy_with_logits loss function for labels\n",
    "def CEloss(y_true, y_pred, n=data_dict['nt']):\n",
    "    loss = 0\n",
    "    for i in range(n):\n",
    "        loss += K.categorical_crossentropy(target=y_true[:,i], output=y_pred[:,i])\n",
    "    loss = (loss/n)*data_dict[\"second_loss_weight\"] # weighing the loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/rrane/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/users/rrane/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/users/rrane/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "if(data_dict['multitask']):\n",
    "        output_mode='error_and_label'\n",
    "        # Configuring the model\n",
    "        prednet = PredNet(stack_sizes, r_stack_sizes, data_dict[\"a_filt_sizes\"], data_dict[\"ahat_filt_sizes\"], \n",
    "                          data_dict[\"r_filt_sizes\"], return_sequences=True, output_mode=output_mode, \n",
    "                          strided_conv_pool=data_dict[\"strided_conv_pool\"], nb_classes=data_dict['nb_classes'],\n",
    "                          lbl_stack_sizes=data_dict['n_chan_lbl_layer']) \n",
    "        # errors will be (batch_size, nt, nb_layers), labels will be (batch_size, nt, num_classes)\n",
    "        errors_and_labels = prednet(inputs)\n",
    "        errors = Lambda(lambda x: x[:,:,:nb_layers], output_shape=(time_steps,nb_layers,))(errors_and_labels)\n",
    "        labels = Lambda(lambda x: x[:,:,nb_layers:], name='label', output_shape=(time_steps,data_dict['nb_classes']))(errors_and_labels)\n",
    "        \n",
    "        # calculate weighted error by layer\n",
    "        errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)],\n",
    "                                         trainable=False)(errors)\n",
    "        # will be (batch_size, nt)\n",
    "        errors_by_time = Flatten()(errors_by_time)  \n",
    "        # weight errors by time\n",
    "        final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False, name='y')(\n",
    "            errors_by_time) \n",
    "\n",
    "        # weighed sum of all label predictions over time\n",
    "#         labels = Lambda(lambda x: K.permute_dimensions(x,(0,2,1)))(labels)\n",
    "        # get_exp_t_weights() returns the weights that start at 0.0 and raise exponentially to 1.0 and plateau. \n",
    "        # Motivated by our prior belief that the model is allowed to slowly learn the right prediction class over time.\n",
    "#         time_label_weights = get_exp_t_weights(time_steps)\n",
    "        # weight labels by time      \n",
    "#         final_labels = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(\n",
    "#             labels)\n",
    "\n",
    "#         final_labels = Flatten(name='label')(final_labels)\n",
    "        # final_labels = labels\n",
    "        model = Model(inputs=inputs, outputs=([final_errors, labels]))\n",
    "        \n",
    "        model.compile(\n",
    "            loss={'y': 'mean_absolute_error', 'label':CEloss }\n",
    "            , optimizer='adam'\n",
    "            , metrics={'y': ['mse'], 'label': ['acc']}\n",
    "            )\n",
    "else:\n",
    "    output_mode='error'\n",
    "    prednet = PredNet(stack_sizes, r_stack_sizes,\n",
    "                      data_dict[\"a_filt_sizes\"], data_dict[\"ahat_filt_sizes\"], data_dict[\"r_filt_sizes\"],\n",
    "                      output_mode=output_mode, return_sequences=True)\n",
    "    errors = prednet(inputs)\n",
    "    \n",
    "    errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)], trainable=False)(errors)  # calculate weighted error by layer\n",
    "    errors_by_time = Flatten()(errors_by_time)  # will be (batch_size, nt)\n",
    "    final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(errors_by_time)  # weight errors by time\n",
    "    model = Model(inputs=inputs, outputs=final_errors)\n",
    "    model.compile(loss=data_dict['loss'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 18, 64, 64, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "pred_net_1 (PredNet)             (None, 18, 13)        6363610     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 18, 5)         0           pred_net_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 18, 1)         6           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18)            0           time_distributed_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "y (Dense)                        (None, 1)             19          flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "label (Lambda)                   (None, 18, 8)         0           pred_net_1[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 6,363,635\n",
      "Trainable params: 6,363,610\n",
      "Non-trainable params: 25\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Sequence generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator that creates sequences for input into PredNet.\n",
    "class SequenceGenerator(Iterator):\n",
    "    def __init__(self, data, nt, labels, data_dict, batch_size=8, shuffle=True, seed=None,\n",
    "                 output_mode='error', sequence_start_mode='all', N_seq=None, n_classes=10,\n",
    "                 data_format=K.image_data_format()):\n",
    "        self.X = data  # X will be like (n_images, nb_cols, nb_rows, nb_channels)\n",
    "        # self.sources = hkl.load(source_file) # source for each image so when creating sequences can assure that consecutive frames are from same video\n",
    "        self.nt = nt\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.n_classes = n_classes\n",
    "        self.data_format = data_format\n",
    "        assert sequence_start_mode in {'all', 'unique'}, 'sequence_start_mode must be in {all, unique}'\n",
    "        self.sequence_start_mode = sequence_start_mode\n",
    "        assert output_mode in {'error', 'prediction', 'label', 'error_and_label', 'prediction_and_label'}, 'output_mode must be in {error, prediction, label, error_and_label, prediction_and_label}'\n",
    "        self.output_mode = output_mode\n",
    "\n",
    "        if self.data_format == 'channels_first':\n",
    "            self.X = np.transpose(self.X, (0, 3, 1, 2))\n",
    "        self.im_shape = self.X[0][0].shape\n",
    "\n",
    "        if self.sequence_start_mode == 'all':  # allow for any possible sequence, starting from any frame\n",
    "            self.possible_starts = np.array(range(0, self.X.shape[1]-self.nt))\n",
    "\n",
    "        if shuffle:\n",
    "            self.possible_starts = np.random.permutation(self.possible_starts)\n",
    "        if N_seq is not None and len(self.possible_starts) > N_seq:  # select a subset of sequences if want to\n",
    "            self.possible_starts = self.possible_starts[:N_seq]\n",
    "        self.N_sequences = len(self.possible_starts)\n",
    "        super(SequenceGenerator, self).__init__(self.X.shape[0], batch_size, shuffle, seed)\n",
    "    \n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        batch_x = np.zeros((current_batch_size, self.nt) + self.im_shape, np.float32)\n",
    "        batch_label = np.zeros((current_batch_size, self.nt, self.n_classes), np.int32)\n",
    "        for i, idx in enumerate(index_array):\n",
    "            vid_idx = np.random.choice(self.possible_starts)\n",
    "            batch_x[i] = self.preprocess(self.X[idx, vid_idx:vid_idx+self.nt])\n",
    "            batch_label[i] = to_categorical(\n",
    "                self.labels[idx, vid_idx:vid_idx+self.nt, 0, -1].astype(int), self.n_classes)\n",
    "        if self.output_mode == 'error':  # model outputs errors, so y should be zeros\n",
    "            batch_y = np.zeros(current_batch_size, np.float32)\n",
    "        elif self.output_mode == 'prediction':  # output actual pixels\n",
    "            batch_y = batch_x\n",
    "        elif 'label' in self.output_mode:\n",
    "            # one_hot_encode the label\n",
    "            labels = batch_label\n",
    "            if self.output_mode == 'label':\n",
    "                batch_y = labels\n",
    "            elif self.output_mode == 'error_and_label':         \n",
    "                batch_y = {'y': np.zeros(current_batch_size, np.float32), 'label': labels}\n",
    "            elif self.output_mode == 'prediction_and_label':            \n",
    "                batch_y = {'y': batch_x, 'label': labels}\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        return X.astype(np.float32) / 255\n",
    "\n",
    "    def create_all(self):\n",
    "        X_all = np.zeros((self.N_sequences, self.nt) + self.im_shape, np.float32)\n",
    "        for i, idx in enumerate(self.possible_starts):\n",
    "            vid_idx = np.random.choice(self.possible_starts)\n",
    "            X_all[i] = self.preprocess(self.X[idx, vid_idx:vid_idx+self.nt])\n",
    "        return X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dict['multitask'] == True:\n",
    "    train_generator = SequenceGenerator(train_data, data_dict['nt'] , train_label, data_dict, batch_size=data_dict['batch_size'], output_mode='error_and_label', n_classes=data_dict[\"nb_classes\"], shuffle=True, seed=seed)\n",
    "    val_generator = SequenceGenerator(val_data, data_dict['nt'] , val_label, data_dict, batch_size=data_dict['batch_size'], output_mode='error_and_label', n_classes=data_dict[\"nb_classes\"], shuffle=False, seed=seed)\n",
    "else:\n",
    "    train_generator = SequenceGenerator(train_data, data_dict['nt'] ,None, data_dict, batch_size=data_dict['batch_size'], n_classes=data_dict[\"nb_classes\"], shuffle=True, seed=seed)\n",
    "    val_generator = SequenceGenerator(val_data, data_dict['nt'] ,None, data_dict, batch_size=data_dict['batch_size'], n_classes=data_dict[\"nb_classes\"], shuffle=False, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X=(32, 18, 64, 64, 1) \t Y=(32, 18, 8)\n",
      "Label [[0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the generator output\n",
    "X, Y = next(val_generator)\n",
    "print(\"shapes X={} \\t Y={}\".format(X.shape, Y['label'].shape))\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, sharex=True, figsize=(nt*2,2))\n",
    "# plot X[0]\n",
    "X = X[0,:,:,:,0]\n",
    "ax.imshow(np.concatenate([t for t in X[:,:,:]], axis=1), interpolation='none', aspect=\"auto\")\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labelleft=False)\n",
    "ax.set_ylabel(r'X[0]', fontsize=10)\n",
    "ax.set_xlim(0,time_steps*im_width)\n",
    "\n",
    "print(\"Label\",Y['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = lambda e : data_dict['lr']*(1 - 0.1*(e//data_dict['lr_reduce_epoch'])) if e//data_dict['lr_reduce_epoch']<10 else 0.1*data_dict['lr']\n",
    "callbacks = [LearningRateScheduler(lr_schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dict['save_model'] == True:\n",
    "    if not os.path.exists(data_dict['weight_dir']): \n",
    "        os.mkdir(data_dict['weight_dir'])\n",
    "        os.chmod(data_dict['weight_dir'], mode=0o777)\n",
    "    callbacks.append(ModelCheckpoint(filepath=data_dict['weights_file'], monitor='val_loss', save_best_only=True))\n",
    "    callbacks.append(EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=25, verbose=1,\n",
    "                          mode='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dict['json_file'], \"w\") as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = data_dict['samples_per_epoch']//data_dict['batch_size'] if data_dict['samples_per_epoch'] is not None else train_generator.n//data_dict['batch_size']\n",
    "validation_steps = int(data_dict['N_seq_val']/data_dict['batch_size']) if  data_dict['N_seq_val'] is not None else val_generator.n//data_dict['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "281/281 [==============================] - 400s - loss: 0.0012 - y_loss: 1.6980e-04 - label_loss: 0.0010 - y_mean_squared_error: 3.6188e-08 - label_acc: 0.1304 - val_loss: 0.0012 - val_y_loss: 1.1618e-04 - val_label_loss: 0.0010 - val_y_mean_squared_error: 1.3859e-08 - val_label_acc: 0.1197\n",
      "Epoch 2/150\n",
      "281/281 [==============================] - 369s - loss: 0.0011 - y_loss: 1.0208e-04 - label_loss: 0.0010 - y_mean_squared_error: 1.0763e-08 - label_acc: 0.1307 - val_loss: 0.0011 - val_y_loss: 9.2061e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 8.7661e-09 - val_label_acc: 0.1202\n",
      "Epoch 3/150\n",
      "281/281 [==============================] - 386s - loss: 0.0011 - y_loss: 8.9199e-05 - label_loss: 0.0010 - y_mean_squared_error: 8.2515e-09 - label_acc: 0.1312 - val_loss: 0.0011 - val_y_loss: 8.2755e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 7.0987e-09 - val_label_acc: 0.1198\n",
      "Epoch 4/150\n",
      "281/281 [==============================] - 385s - loss: 0.0011 - y_loss: 8.0247e-05 - label_loss: 0.0010 - y_mean_squared_error: 6.6856e-09 - label_acc: 0.1310 - val_loss: 0.0011 - val_y_loss: 7.6627e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 6.1023e-09 - val_label_acc: 0.1204\n",
      "Epoch 5/150\n",
      "281/281 [==============================] - 385s - loss: 0.0011 - y_loss: 7.3190e-05 - label_loss: 0.0010 - y_mean_squared_error: 5.5863e-09 - label_acc: 0.1312 - val_loss: 0.0011 - val_y_loss: 6.9417e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 5.0328e-09 - val_label_acc: 0.1208\n",
      "Epoch 6/150\n",
      "281/281 [==============================] - 386s - loss: 0.0011 - y_loss: 6.8232e-05 - label_loss: 0.0010 - y_mean_squared_error: 4.8798e-09 - label_acc: 0.1301 - val_loss: 0.0011 - val_y_loss: 6.4629e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 4.3731e-09 - val_label_acc: 0.1179\n",
      "Epoch 7/150\n",
      "281/281 [==============================] - 369s - loss: 0.0011 - y_loss: 6.4893e-05 - label_loss: 0.0010 - y_mean_squared_error: 4.4278e-09 - label_acc: 0.1318 - val_loss: 0.0011 - val_y_loss: 6.0749e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 3.8744e-09 - val_label_acc: 0.1200\n",
      "Epoch 8/150\n",
      "281/281 [==============================] - 385s - loss: 0.0011 - y_loss: 6.0270e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.8317e-09 - label_acc: 0.1297 - val_loss: 0.0011 - val_y_loss: 5.7627e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 3.4929e-09 - val_label_acc: 0.1197\n",
      "Epoch 9/150\n",
      "281/281 [==============================] - 385s - loss: 0.0011 - y_loss: 5.8651e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.6457e-09 - label_acc: 0.1311 - val_loss: 0.0011 - val_y_loss: 5.5100e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 3.2064e-09 - val_label_acc: 0.1206\n",
      "Epoch 10/150\n",
      "281/281 [==============================] - 386s - loss: 0.0011 - y_loss: 5.4611e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.1579e-09 - label_acc: 0.1304 - val_loss: 0.0011 - val_y_loss: 5.3750e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 3.0518e-09 - val_label_acc: 0.1182\n",
      "Epoch 11/150\n",
      "281/281 [==============================] - 385s - loss: 0.0011 - y_loss: 5.4295e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.1292e-09 - label_acc: 0.1304 - val_loss: 0.0011 - val_y_loss: 5.3054e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.9746e-09 - val_label_acc: 0.1175\n",
      "Epoch 12/150\n",
      "281/281 [==============================] - 380s - loss: 0.0011 - y_loss: 5.2105e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.8859e-09 - label_acc: 0.1312 - val_loss: 0.0011 - val_y_loss: 5.2481e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.9134e-09 - val_label_acc: 0.1208\n",
      "Epoch 13/150\n",
      "281/281 [==============================] - 372s - loss: 0.0011 - y_loss: 5.3168e-05 - label_loss: 0.0010 - y_mean_squared_error: 3.0263e-09 - label_acc: 0.1306 - val_loss: 0.0011 - val_y_loss: 5.0758e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.7362e-09 - val_label_acc: 0.1218\n",
      "Epoch 14/150\n",
      "281/281 [==============================] - 385s - loss: 0.0011 - y_loss: 5.2020e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.8865e-09 - label_acc: 0.1308 - val_loss: 0.0011 - val_y_loss: 4.9372e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.5943e-09 - val_label_acc: 0.1172\n",
      "Epoch 15/150\n",
      "281/281 [==============================] - 385s - loss: 0.0011 - y_loss: 5.2195e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.9193e-09 - label_acc: 0.1299 - val_loss: 0.0011 - val_y_loss: 4.8734e-05 - val_label_loss: 0.0010 - val_y_mean_squared_error: 2.5307e-09 - val_label_acc: 0.1220\n",
      "Epoch 16/150\n",
      " 60/281 [=====>........................] - ETA: 290s - loss: 0.0011 - y_loss: 4.8560e-05 - label_loss: 0.0010 - y_mean_squared_error: 2.5336e-09 - label_acc: 0.1273"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=data_dict['nb_epochs'],\n",
    "                              callbacks=callbacks, \n",
    "                              validation_data=val_generator, \n",
    "                              validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training history to a file\n",
    "with open(os.path.join(data_dict['result_dir'], 'training_history.json'), 'w') as f:\n",
    "    json.dump(history.history, f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading best model\n",
    "# data_dict['json_file'] = os.path.join(os.path.join(os.getcwd(), \"mnist_best_prednet\"), 'prednet_mnist_model.json')\n",
    "# data_dict['weights_file'] = os.path.join(os.path.join(os.getcwd(), \"mnist_best_prednet\"), 'prednet_mnist_weights.hdf5')\n",
    "\n",
    "# Loading trained model\n",
    "with open(data_dict['json_file'], 'r') as f:\n",
    "    json_string = f.read()\n",
    "\n",
    "model = model_from_json(json_string, custom_objects={'PredNet': PredNet, 'nb_layers':nb_layers})\n",
    "model.load_weights(data_dict['weights_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing model (to output predictions)\n",
    "layer_config = model.layers[1].get_config()\n",
    "if(data_dict[\"multitask\"]):\n",
    "    output_mode = 'prediction_and_label' \n",
    "else:\n",
    "    output_mode = 'prediction'\n",
    "layer_config['output_mode'] = output_mode\n",
    "data_format = layer_config['data_format'] if 'data_format' in layer_config else layer_config['dim_ordering']\n",
    "test_prednet = PredNet(weights=model.layers[1].get_weights(), **layer_config)\n",
    "input_shape = list(model.layers[0].batch_input_shape[1:])\n",
    "input_shape[0] = time_steps\n",
    "inputs = Input(shape=tuple(input_shape))\n",
    "predictions = test_prednet(inputs)\n",
    "test_model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #initialize lists for evaluation        \n",
    "mse_model_list, mse_prev_list, mae_model_list, mae_prev_list = ([] for i in range(4))\n",
    "psnr_list, ssim_list, sharpness_grad_list, psnr_prev_list, ssim_prev_list, sharpness_grad_prev_list = ([] for i in range(6))\n",
    "psnr_movement_list, psnr_movement_prev_list, ssim_movement_list, ssim_movement_prev_list =  ([] for i in range(4))\n",
    "conditioned_ssim_list, sharpness_list, sharpness_prev_list = ([] for i in range(3))\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  adhoc to speed things up \n",
    "data_dict['batch_size'] = 128\n",
    "max_test_batches = val_generator.n // 1210 # adhoc, only run on few batches (/8)\n",
    "\n",
    "for index, data in enumerate(val_generator):\n",
    "    # Only consider steps_test number of steps\n",
    "    if index > max_test_batches:\n",
    "        break\n",
    "    # X_test = test_generator.next()[0]\n",
    "    X_test = data[0]        \n",
    "\n",
    "    if(data_dict['multitask']==True):\n",
    "        lbl = data[1]['label']\n",
    "        lbl_final = lbl.argmax(axis=-1)\n",
    "        X_hat_with_lbl = test_model.predict(X_test, data_dict['batch_size'])\n",
    "        X_hat, lbl_hat = X_hat_with_lbl[:,:,:-data_dict[\"nb_classes\"]], X_hat_with_lbl[:,:,-data_dict[\"nb_classes\"]:]\n",
    "        # print(\"<d>\", lbl_hat.shape, lbl_hat.max(), lbl_hat.min(), lbl_hat.mean())\n",
    "        X_hat  = np.reshape(X_hat, X_test.shape) \n",
    "#         lbl_pred_final_logits = np.moveaxis(lbl_hat,1,2).dot(get_exp_t_weights(time_steps)).squeeze()\n",
    "        lbl_pred_final = lbl_hat.argmax(axis=-1)\n",
    "        if index==0: \n",
    "            # visualize the predicted labels for the first round\n",
    "            for i in range(-data_dict['nt']-3,-data_dict['nt']):\n",
    "                print(\"\\nExpected labels  = \\n\", [directions[l] for l in lbl_final[i]]) \n",
    "                print(\"Predicted labels = \\n\", [directions[l] for l in lbl_pred_final[i]])\n",
    "        acc = (lbl_pred_final == lbl_final).mean()\n",
    "        print(\"{}, accuracy= {:.2f}%\".format(index, acc*100))\n",
    "        accuracy_list.append(acc)\n",
    "    else:\n",
    "        X_hat = test_model.predict(X_test, data_dict['batch_size'])\n",
    "    if data_format == 'channels_first':\n",
    "        X_test = np.transpose(X_test, (0, 1, 3, 4, 2))\n",
    "        X_hat = np.transpose(X_hat, (0, 1, 3, 4, 2))\n",
    "\n",
    "    # Compare the scores of PredNet predictions vs. using last frame.  Write results to prediction_scores.txt\n",
    "    # mean square error\n",
    "    mse_model_list.append(\n",
    "        np.mean((X_test[:, 1:] - X_hat[:, 1:]) ** 2))  # look at all timesteps except the first\n",
    "    mse_prev_list.append(np.mean((X_test[:, :-1] - X_test[:, 1:]) ** 2))\n",
    "    # mean absolute error\n",
    "    mae_model_list.append(\n",
    "        np.mean(np.abs(X_test[:, 1:] - X_hat[:, 1:])))\n",
    "    mae_prev_list.append(np.mean(np.abs(X_test[:, :-1] - X_test[:, 1:])))\n",
    "    # ssim\n",
    "    ssim_list.append(np.mean([return_difference(X_test[ind][1:], X_hat[ind][1:])[0] for ind in range(X_test.shape[0])]))\n",
    "    ssim_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[0] \n",
    "                                   for ind in range(X_test.shape[0]-1)]))\n",
    "    ssim_movement_list.append(np.mean([return_difference(X_test[ind], X_hat[ind])[2] \n",
    "                                       for ind in range(X_test.shape[0])]))\n",
    "    ssim_movement_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[2] \n",
    "                                   for ind in range(X_test.shape[0]-1)])) \n",
    "    conditioned_ssim_list.append(np.mean([conditioned_ssim(X_test[ind], X_hat[ind]) \n",
    "                                   for ind in range(X_test.shape[0])])) \n",
    "\n",
    "    # psnr\n",
    "    psnr_list.append(np.mean([return_difference(X_test[ind][1:], X_hat[ind][1:])[1] for ind in range(X_test.shape[0])]))            \n",
    "    psnr_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[1] \n",
    "                                   for ind in range(X_test.shape[0]-1)]))\n",
    "    psnr_movement_list.append(np.mean([return_difference(X_test[ind], X_hat[ind])[3] \n",
    "                                       for ind in range(X_test.shape[0])]))\n",
    "    psnr_movement_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[3] \n",
    "                                   for ind in range(X_test.shape[0]-1)]))\n",
    "\n",
    "    # sharpness\n",
    "#     sharpness_grad_list.append(np.mean([sharpness_difference_grad(X_test[ind][1:], X_hat[ind][1:])\n",
    "#                                    for ind in range(X_test.shape[0])]))\n",
    "    #sharpness_grad_prev_list.append(np.mean([sharpness_difference_grad(X_test[ind][:-1], X_test[ind][1:])\n",
    "    #                                    for ind in range(X_test.shape[0]-1)]))\n",
    "\n",
    "#     sharpness_list.append(np.mean([sharpness_difference(X_test[ind][1:], X_hat[ind][1:])\n",
    "#                                   for ind in range(X_test.shape[0])]))\n",
    "    #sharpness_prev_list.append(np.mean([sharpness_difference(X_test[ind][:-1], X_test[ind][1:])\n",
    "    #                               for ind in range(X_test.shape[0])]))\n",
    "\n",
    "# save in a dict and limit the size of float decimals to max 6\n",
    "results_dict = {                    \n",
    "\"MSE_mean\": float(\"{:.10f}\".format(np.mean(mse_model_list))), \n",
    "\"MSE_std\":float((\"{:.10f}\".format(np.std(mse_model_list)))), \n",
    "\"MSE_mean_prev_frame_copy\":float(\"{:.10f}\".format(np.mean(mse_prev_list))), \n",
    "\"MSE_std_prev_frame_copy\":float(\"{:.10f}\".format(np.std(mse_prev_list))),\n",
    "\"MAE_mean\": float(\"{:.6f}\".format(np.mean(mae_model_list))), \n",
    "\"MAE_std\":float((\"{:.6f}\".format(np.std(mae_model_list)))), \n",
    "\"MAE_mean_prev_frame_copy\":float(\"{:.6f}\".format(np.mean(mae_prev_list))), \n",
    "\"MAE_std_prev_frame_copy\":float(\"{:.6f}\".format(np.std(mae_prev_list))),\n",
    "\"SSIM_mean\": float(\"{:.6f}\".format(np.mean(ssim_list))), \n",
    "\"SSIM_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(ssim_prev_list))), \n",
    "\"SSIM_movement_mean\": float(\"{:.6f}\".format(np.mean(ssim_movement_list))), \n",
    "\"SSIM_movement_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(ssim_movement_prev_list))), \n",
    "\"Conditioned_SSIM_mean\": float(\"{:.6f}\".format(np.mean(conditioned_ssim_list))),\n",
    "\"PSNR_mean\": float(\"{:.6f}\".format(np.mean(psnr_list))),\n",
    "\"PSNR_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(psnr_prev_list))), \n",
    "\"PSNR_movement_mean\": float(\"{:.6f}\".format(np.mean(psnr_movement_list))), \n",
    "\"PSNR_movement_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(psnr_movement_prev_list))), \n",
    "\"Sharpness_grad_mean\": float(\"{:.6f}\".format(np.mean(sharpness_grad_list))),\n",
    "#\"Sharpness_grad_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(sharpness_grad_prev_list))),\n",
    "\"Sharpness_difference_mean\": float(\"{:.6f}\".format(np.mean(sharpness_list)))\n",
    "#\"Sharpness_difference_mean_prev_frame_copy\" : float(\"{:.6f}\".format(np.mean(sharpness_prev_list)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model results for training dataset:\", results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dict['result_dir'], 'mnist_scores.json'), 'w') as f:\n",
    "    json.dump(results_dict, f, sort_keys=True,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating extra plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_plot_flag = False\n",
    "\n",
    "plot_save_dir = os.path.join(data_dict['result_dir'], 'predictions')\n",
    "if not os.path.exists(plot_save_dir):\n",
    "    os.makedirs(plot_save_dir)\n",
    "\n",
    "assert X_test.shape==X_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extra_plot_flag:\n",
    "    #Create models for error and R plots\n",
    "    extra_test_models = []\n",
    "    no_layers = len(test_prednet.stack_sizes)\n",
    "    extra_output_modes = (['E'+str(no) for no in range(no_layers)] + ['A'+str(no) for no in range(no_layers)] \n",
    "                        + ['Ahat'+str(no) for no in range(no_layers)] + ['R'+str(no) for no in range(no_layers)])\n",
    "\n",
    "    for output_mode in extra_output_modes:\n",
    "        if(data_dict['multitask'] == True):\n",
    "            output_mode += \"_and_label\"\n",
    "        layer_config['output_mode'] = output_mode    \n",
    "        data_format = (layer_config['data_format'] if 'data_format' in layer_config \n",
    "                        else layer_config['dim_ordering'])\n",
    "        extra_test_prednet = PredNet(weights=model.layers[1].get_weights(), **layer_config)\n",
    "        input_shape = list(model.layers[0].batch_input_shape[1:])\n",
    "        input_shape[0] = data_dict['nt']\n",
    "        inputs = Input(shape=tuple(input_shape))\n",
    "        extra_predictions = extra_test_prednet(inputs)\n",
    "        extra_test_model = Model(inputs=inputs, outputs=extra_predictions)\n",
    "        extra_test_models.append((extra_test_model, output_mode))\n",
    "    \n",
    "    #Create outputs for extra plots\n",
    "    error_X_hats = []\n",
    "    R_X_hats = []\n",
    "    A_X_hats = []\n",
    "    Ahat_X_hats = []\n",
    "    for test_model, output_mode in extra_test_models:\n",
    "        if output_mode[0]=='R':\n",
    "            R_X_hat = test_model.predict(X_test) \n",
    "            R_X_hats.append((R_X_hat, output_mode))\n",
    "        elif output_mode[0]=='E':\n",
    "            error_X_hat = test_model.predict(X_test) \n",
    "            error_X_hats.append((error_X_hat, output_mode))\n",
    "        elif 'Ahat' in output_mode: \n",
    "            Ahat_X_hat = test_model.predict(X_test) \n",
    "            Ahat_X_hats.append((Ahat_X_hat, output_mode))\n",
    "        else: # output_mode[0]=='A':\n",
    "            A_X_hat = test_model.predict(X_test) \n",
    "            A_X_hats.append((A_X_hat, output_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample 'plots_per_grp' videos from each sub-group\n",
    "aspect_ratio = float(X_hat.shape[2]) / X_hat.shape[3]\n",
    "for i in range(3):      #len(X_test)    \n",
    "    if extra_plot_flag:\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=20, sharex=True, figsize=(time_steps, 25 * aspect_ratio),\n",
    "                              gridspec_kw={'height_ratios':[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,3,3]})\n",
    "    else:\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=2, sharex=True, figsize=(time_steps, 2 * aspect_ratio))\n",
    "\n",
    "    # set the title of the plot as the label and the video ID for reference\n",
    "    if(data_dict['multitask']):\n",
    "        title = \"{}) TRUE {}\\n PRED: {}\".format(\n",
    "        i, \n",
    "        [directions[lbl] for lbl in lbl_final[i]],\n",
    "        [directions[lbl] for lbl in lbl_pred_final[i]])\n",
    "    else:\n",
    "        title = \"{}) Digit {}\".format( # Pos {}\n",
    "        i, \n",
    "        np.unique(val_label[i,0,:,0].astype(int))\n",
    "#         ,val_label[i,:,0,1:]\n",
    ")\n",
    "\n",
    "    fig.suptitle(title, fontsize=10)\n",
    "\n",
    "    #Plot video\n",
    "    ax = plt.subplot()\n",
    "    ax.imshow(np.concatenate([t for t in X_test[i,:,:,:,0]], axis=1), interpolation='none', aspect=\"auto\")\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False,\n",
    "                                    labelbottom=False, labelleft=False)\n",
    "    ax.set_ylabel(r'Actual', fontsize=10)\n",
    "    ax.set_xlim(0,time_steps*im_width)\n",
    "\n",
    "    #Plot predictions\n",
    "    divider = make_axes_locatable(ax)\n",
    "    ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                             \n",
    "    ax.imshow(np.concatenate([t for t in X_hat[i,:,:,:,0]], axis=1), interpolation='none', aspect=\"auto\")\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False,\n",
    "                                    labelbottom=False, labelleft=False)\n",
    "    ax.set_ylabel(r'Prediction', fontsize=10)\n",
    "    ax.set_xlim(0,time_steps*im_width)\n",
    "    \n",
    "    if extra_plot_flag:\n",
    "        #Create values for R plots      \n",
    "        results = plot_changes_in_r(R_X_hats, i, std_param=data_dict['std_param'])\n",
    "        ax = divider.append_axes(\"bottom\", size=\"300%\", pad=0.2)                                                                \n",
    "        #Plot R plots\n",
    "        for layer in results:\n",
    "            (y,x,std) = layer[0]\n",
    "            x = [im_width/2+item*im_width for item in x]\n",
    "            ax.fill_between(x, [(val-data_dict['std_param']*dev) for val,dev in zip(y,std)], \n",
    "                             [(val+data_dict['std_param']*dev) for val,dev in zip(y,std)], alpha=0.1)\n",
    "            ax.plot(x, y)\n",
    "\n",
    "        ax.set_xlim(0,time_steps*im_width)\n",
    "        ax.set_xticks(np.arange(im_width/2, time_steps*im_width, step=im_width))                \n",
    "        ax.set_xticklabels(np.arange(1,time_steps+1))\n",
    "        ax.grid(True)                  \n",
    "        ax.set_ylabel(r\"Mean R activations\", fontsize=10)\n",
    "        ax.xaxis.set_label_position('top') \n",
    "        ax.legend(['R'+str(no) for no in range(no_layers)], loc='center left')\n",
    "\n",
    "        #Create values for E plots      \n",
    "        results = plot_changes_in_r(error_X_hats, i, std_param=data_dict['std_param'])\n",
    "        ax = divider.append_axes(\"bottom\", size=\"300%\", pad=0.2)                                                                \n",
    "        #Plot E plots\n",
    "        for layer in results:\n",
    "            (y,x,std) = layer[0]\n",
    "            x = [im_width/2+item*im_width for item in x]\n",
    "            ax.fill_between(x, [(val-data_dict['std_param']*dev) for val,dev in zip(y,std)], \n",
    "                            [(val+data_dict['std_param']*dev) for val,dev in zip(y,std)], alpha=0.1)\n",
    "            ax.plot(x, y)\n",
    "\n",
    "        ax.set_xlim(0,time_steps*im_width)\n",
    "        ax.set_xticks(np.arange(im_width/2, time_steps*im_width, step=im_width))                \n",
    "        ax.set_xticklabels(np.arange(1,time_steps+1))\n",
    "        ax.grid(True)                  \n",
    "        ax.set_ylabel(r\"Mean E activations\", fontsize=10)\n",
    "        ax.xaxis.set_label_position('top') \n",
    "        ax.legend(['E'+str(no) for no in range(no_layers)], loc='center left')\n",
    "\n",
    "        #Create error output matrices to plot inside the next loop\n",
    "        R_matrices = plot_errors(R_X_hats, X_test, ind=i)\n",
    "        A_matrices =  plot_errors(A_X_hats, X_test, ind=i) \n",
    "        Ahat_matrices = plot_errors(Ahat_X_hats, X_test, ind=i)\n",
    "        error_matrices = plot_errors(error_X_hats, X_test, ind=i)\n",
    "        #Plot R, A, Ahat and errors for each layer\n",
    "        for layer in range(len(error_matrices)):   \n",
    "                ##R\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.2)                                             \n",
    "                ax.imshow(np.concatenate([t for t in R_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"R\" + str(layer), fontsize=10)\n",
    "                ax.set_xlabel(r\"Layer \" + str(layer), fontsize=10)\n",
    "                ax.xaxis.set_label_position('top') \n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "                ##A\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                             \n",
    "                ax.imshow(np.concatenate([t for t in Ahat_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"Ahat\" + str(layer), fontsize=10)\n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "                ##Ahat\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                     \n",
    "                ax.imshow(np.concatenate([t for t in A_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"A\" + str(layer), fontsize=10)\n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "                ##E\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                             \n",
    "                ax.imshow(np.concatenate([t for t in error_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"E\" + str(layer), fontsize=10)\n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(plot_save_dir+\"/\"+\"prediction\"+str(i))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
