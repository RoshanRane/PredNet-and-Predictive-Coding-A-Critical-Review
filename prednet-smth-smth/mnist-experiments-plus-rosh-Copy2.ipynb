{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras, keras_preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import LSTM, Lambda\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.models import load_model\n",
    "from keras.models import Model, model_from_json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from viz_utils import plot_loss_curves, plot_errors, plot_changes_in_r, return_difference\n",
    "from viz_utils import conditioned_ssim, sharpness_difference_grad, sharpness, sharpness_difference\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "plt.rcParams['figure.figsize'] = 30,15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz_utils import *\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old models folder\n",
    "suffix = \"1ss\" # set to \"\" for 4 numbers\n",
    "out_folder = \"moving_mnist_results\"\n",
    "seed = None\n",
    "# np.random.seed(seed)\n",
    "# tf.set_random_seed(seed)\n",
    "\n",
    "data_dict = {\n",
    "    \"weight_dir\" : os.path.join(os.getcwd(), out_folder),\n",
    "    \"result_dir\" : os.path.join(os.getcwd(), out_folder, \"results\"),\n",
    "    \"json_file\" : os.path.join(os.getcwd(), out_folder, \"model.json\"),\n",
    "    \"weights_file\": os.path.join(os.path.join(os.getcwd(), out_folder), 'prednet_mnist_weights.hdf5'),\n",
    "    \"json_file\": os.path.join(os.path.join(os.getcwd(), out_folder), 'prednet_mnist_model.json'),\n",
    "    \"nt\": 18,\n",
    "    \"datafile\" : \"../data/data{}.npy\".format(suffix),\n",
    "    \"datalabelsfile\" : \"../data/data{}_labels.npy\".format(suffix),\n",
    "    \"nval\" : 1000,\n",
    "    \"nb_epochs\" : 150,\n",
    "    \"batch_size\" : 32,\n",
    "    \"samples_per_epoch\" : None,\n",
    "    \"N_seq_val\" : None,\n",
    "    \"n_channels\" : 1,\n",
    "    \"im_height\" : 64,\n",
    "    \"im_width\" : 64,\n",
    "    \"n_chan_layer\" : [32, 64, 96, 128], #(1,32,64,128,256)\n",
    "    \"n_chan_R_layer\" : [],\n",
    "    \"layer_loss\" : [1., 0., 0., 0., 0.],\n",
    "    \"a_filt_sizes\": (3, 3, 3, 3),\n",
    "    \"ahat_filt_sizes\": (3, 3, 3, 3, 3),\n",
    "    \"r_filt_sizes\": (3, 3, 3, 3, 3),\n",
    "    \"lr\": 0.0003, # 0.001- 0.0008 - 0.0005 - 0.0001\n",
    "    \"lr_reduce_epoch\": 10,\n",
    "    \"multitask\": True,\n",
    "    \"std_param\": 0.5,\n",
    "    \"strided_conv_pool\": False,\n",
    "    \"nb_classes\" : 8,\n",
    "    \"n_chan_lbl_layer\" : [256],\n",
    "    \"second_loss_weight\":0.0000\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset ../data/data1ss.npy with shape=(10000, 20, 1, 64, 64)\n",
      "train split shape=(9000, 20, 64, 64, 1)\t val split shape=(1000, 20, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load moving numbers dataset\n",
    "data = np.load(data_dict[\"datafile\"]).astype(float) / 255\n",
    "labels = np.load(data_dict[\"datalabelsfile\"])\n",
    "print(\"loaded dataset {} with shape={}\".format(data_dict[\"datafile\"], data.shape))\n",
    "# move channel axis to the end and split into train and test\n",
    "data = np.moveaxis(data, 2, -1)\n",
    "\n",
    "_n = 0\n",
    "train_data = data[_n:-data_dict[\"nval\"],]\n",
    "val_data = data[-data_dict[\"nval\"]:,]\n",
    "train_label = labels[_n:-data_dict[\"nval\"]]\n",
    "val_label = labels[-data_dict[\"nval\"]:]\n",
    "assert train_data.shape[0] == train_label.shape[0]\n",
    "assert val_data.shape[0] == val_label.shape[0]\n",
    "\n",
    "n, nt, im_height, im_width, n_channels =  train_data.shape\n",
    "print(\"train split shape={}\\t val split shape={}\".format(train_data.shape, val_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformulate as a 8-class classification problem\n",
    "directions = [\"left\",\"top-left\",\"top\",\"top-right\",\n",
    "              \"right\",\"bot-right\",\"bot\",\"bot-left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3888x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 5 samples\n",
    "rand_idxs = np.random.randint(0, len(train_data), 1)\n",
    "\n",
    "n = data_dict[\"nt\"] if data_dict[\"nt\"]<=8 else 8 \n",
    "for i in rand_idxs:\n",
    "    x = train_data[i]\n",
    "    label = labels[i]\n",
    "        \n",
    "    f,axs = plt.subplots(1,n,figsize=(3*data_dict[\"nt\"],4))\n",
    "    for j in range(n):\n",
    "        axs[j].axis(\"off\")\n",
    "        axs[j].imshow(x[j].squeeze())\n",
    "        axs[j].set_title(directions[int(label[j,0,-1])], fontdict = {'fontsize' : 400//data_dict[\"nt\"]})\n",
    "        \n",
    "    plt.subplots_adjust(wspace=0.0001, hspace=0.0001)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prednet import PredNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weight directory if it does not exist\n",
    "if not os.path.exists(data_dict[\"weight_dir\"]):\n",
    "    os.makedirs(data_dict[\"weight_dir\"])\n",
    "    os.chmod(data_dict['weight_dir'], mode=0o777)\n",
    "    \n",
    "if not os.path.exists(data_dict[\"result_dir\"]):\n",
    "    os.makedirs(data_dict[\"result_dir\"])\n",
    "    os.chmod(data_dict['result_dir'], mode=0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels, im_height, im_width = (data_dict['n_channels'], data_dict['im_height'], data_dict['im_width'])\n",
    "input_shape = (n_channels, im_height, im_width) if K.image_data_format() == 'channels_first' else (\n",
    "        im_height, im_width, n_channels)\n",
    "stack_sizes = tuple([data_dict[\"n_channels\"]] + data_dict[\"n_chan_layer\"])\n",
    "if(len(data_dict[\"n_chan_R_layer\"]) != 0): \n",
    "    r_stack_sizes = tuple([data_dict[\"n_channels\"]] + data_dict[\"n_chan_R_layer\"])\n",
    "else:\n",
    "    r_stack_sizes = stack_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting for each layer in final loss; \"L_0\" model:  [1, 0, 0, 0], \"L_all\": [1, 0.1, 0.1, 0.1]\n",
    "# Checking if all the values in layer_loss are between 0.0 and 1.0\n",
    "# Checking if the length of all layer loss list is equal to the number of prednet layers\n",
    "assert all(1.0 >= i >= 0.0 for i in data_dict[\"layer_loss\"]) and len(data_dict[\"layer_loss\"]) == len(stack_sizes)\n",
    "layer_loss_weights = np.array(data_dict[\"layer_loss\"])\n",
    "layer_loss_weights = np.expand_dims(layer_loss_weights, 1)\n",
    "\n",
    "# equally weight all timesteps except the first\n",
    "time_steps = data_dict[\"nt\"]\n",
    "time_loss_weights = 1. / (time_steps - 1) * np.ones((time_steps, 1))\n",
    "time_loss_weights[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(time_steps,) + input_shape)\n",
    "nb_layers = len(data_dict['n_chan_layer'])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse_categorial_crossentropy_with_logits loss function for labels\n",
    "def CEloss(y_true, y_pred, n=data_dict['nt']):\n",
    "    loss = 0\n",
    "    for i in range(n):\n",
    "        loss += K.categorical_crossentropy(target=y_true[:,i], output=y_pred[:,i])\n",
    "    loss = (loss/n)*data_dict[\"second_loss_weight\"] # weighing the loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/rrane/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/users/rrane/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/users/rrane/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "if(data_dict['multitask']):\n",
    "        output_mode='error_and_label'\n",
    "        # Configuring the model\n",
    "        prednet = PredNet(stack_sizes, r_stack_sizes, data_dict[\"a_filt_sizes\"], data_dict[\"ahat_filt_sizes\"], \n",
    "                          data_dict[\"r_filt_sizes\"], return_sequences=True, output_mode=output_mode, \n",
    "                          strided_conv_pool=data_dict[\"strided_conv_pool\"], nb_classes=data_dict['nb_classes'],\n",
    "                          lbl_stack_sizes=data_dict['n_chan_lbl_layer']) \n",
    "        # errors will be (batch_size, nt, nb_layers), labels will be (batch_size, nt, num_classes)\n",
    "        errors_and_labels = prednet(inputs)\n",
    "        errors = Lambda(lambda x: x[:,:,:nb_layers], output_shape=(time_steps,nb_layers,))(errors_and_labels)\n",
    "        labels = Lambda(lambda x: x[:,:,nb_layers:], name='label', output_shape=(time_steps,data_dict['nb_classes']))(errors_and_labels)\n",
    "        \n",
    "        # calculate weighted error by layer\n",
    "        errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)],\n",
    "                                         trainable=False)(errors)\n",
    "        # will be (batch_size, nt)\n",
    "        errors_by_time = Flatten()(errors_by_time)  \n",
    "        # weight errors by time\n",
    "        final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False, name='y')(\n",
    "            errors_by_time) \n",
    "\n",
    "        # weighed sum of all label predictions over time\n",
    "#         labels = Lambda(lambda x: K.permute_dimensions(x,(0,2,1)))(labels)\n",
    "        # get_exp_t_weights() returns the weights that start at 0.0 and raise exponentially to 1.0 and plateau. \n",
    "        # Motivated by our prior belief that the model is allowed to slowly learn the right prediction class over time.\n",
    "#         time_label_weights = get_exp_t_weights(time_steps)\n",
    "        # weight labels by time      \n",
    "#         final_labels = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(\n",
    "#             labels)\n",
    "\n",
    "#         final_labels = Flatten(name='label')(final_labels)\n",
    "        # final_labels = labels\n",
    "        model = Model(inputs=inputs, outputs=([final_errors, labels]))\n",
    "        \n",
    "        model.compile(\n",
    "            loss={'y': 'mean_absolute_error', 'label':CEloss }\n",
    "            , optimizer='adam'\n",
    "            , metrics={'y': ['mse'], 'label': ['acc']}\n",
    "            )\n",
    "else:\n",
    "    output_mode='error'\n",
    "    prednet = PredNet(stack_sizes, r_stack_sizes,\n",
    "                      data_dict[\"a_filt_sizes\"], data_dict[\"ahat_filt_sizes\"], data_dict[\"r_filt_sizes\"],\n",
    "                      output_mode=output_mode, return_sequences=True)\n",
    "    errors = prednet(inputs)\n",
    "    \n",
    "    errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)], trainable=False)(errors)  # calculate weighted error by layer\n",
    "    errors_by_time = Flatten()(errors_by_time)  # will be (batch_size, nt)\n",
    "    final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(errors_by_time)  # weight errors by time\n",
    "    model = Model(inputs=inputs, outputs=final_errors)\n",
    "    model.compile(loss=data_dict['loss'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 18, 64, 64, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "pred_net_1 (PredNet)             (None, 18, 13)        7416794     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 18, 5)         0           pred_net_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 18, 1)         6           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 18)            0           time_distributed_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "y (Dense)                        (None, 1)             19          flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "label (Lambda)                   (None, 18, 8)         0           pred_net_1[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 7,416,819\n",
      "Trainable params: 7,416,794\n",
      "Non-trainable params: 25\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Sequence generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator that creates sequences for input into PredNet.\n",
    "class SequenceGenerator(Iterator):\n",
    "    def __init__(self, data, nt, labels, data_dict, batch_size=8, shuffle=True, seed=None,\n",
    "                 output_mode='error', sequence_start_mode='all', N_seq=None, n_classes=10,\n",
    "                 data_format=K.image_data_format()):\n",
    "        self.X = data  # X will be like (n_images, nb_cols, nb_rows, nb_channels)\n",
    "        # self.sources = hkl.load(source_file) # source for each image so when creating sequences can assure that consecutive frames are from same video\n",
    "        self.nt = nt\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.n_classes = n_classes\n",
    "        self.data_format = data_format\n",
    "        assert sequence_start_mode in {'all', 'unique'}, 'sequence_start_mode must be in {all, unique}'\n",
    "        self.sequence_start_mode = sequence_start_mode\n",
    "        assert output_mode in {'error', 'prediction', 'label', 'error_and_label', 'prediction_and_label'}, 'output_mode must be in {error, prediction, label, error_and_label, prediction_and_label}'\n",
    "        self.output_mode = output_mode\n",
    "\n",
    "        if self.data_format == 'channels_first':\n",
    "            self.X = np.transpose(self.X, (0, 3, 1, 2))\n",
    "        self.im_shape = self.X[0][0].shape\n",
    "\n",
    "        if self.sequence_start_mode == 'all':  # allow for any possible sequence, starting from any frame\n",
    "            self.possible_starts = np.array(range(0, self.X.shape[1]-self.nt))\n",
    "\n",
    "        if shuffle:\n",
    "            self.possible_starts = np.random.permutation(self.possible_starts)\n",
    "        if N_seq is not None and len(self.possible_starts) > N_seq:  # select a subset of sequences if want to\n",
    "            self.possible_starts = self.possible_starts[:N_seq]\n",
    "        self.N_sequences = len(self.possible_starts)\n",
    "        super(SequenceGenerator, self).__init__(self.X.shape[0], batch_size, shuffle, seed)\n",
    "    \n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        batch_x = np.zeros((current_batch_size, self.nt) + self.im_shape, np.float32)\n",
    "        batch_label = np.zeros((current_batch_size, self.nt, self.n_classes), np.int32)\n",
    "        for i, idx in enumerate(index_array):\n",
    "            vid_idx = np.random.choice(self.possible_starts)\n",
    "            batch_x[i] = self.preprocess(self.X[idx, vid_idx:vid_idx+self.nt])\n",
    "            batch_label[i] = to_categorical(\n",
    "                self.labels[idx, vid_idx:vid_idx+self.nt, 0, -1].astype(int), self.n_classes)\n",
    "        if self.output_mode == 'error':  # model outputs errors, so y should be zeros\n",
    "            batch_y = np.zeros(current_batch_size, np.float32)\n",
    "        elif self.output_mode == 'prediction':  # output actual pixels\n",
    "            batch_y = batch_x\n",
    "        elif 'label' in self.output_mode:\n",
    "            # one_hot_encode the label\n",
    "            labels = batch_label\n",
    "            if self.output_mode == 'label':\n",
    "                batch_y = labels\n",
    "            elif self.output_mode == 'error_and_label':         \n",
    "                batch_y = {'y': np.zeros(current_batch_size, np.float32), 'label': labels}\n",
    "            elif self.output_mode == 'prediction_and_label':            \n",
    "                batch_y = {'y': batch_x, 'label': labels}\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        return X.astype(np.float32) / 255\n",
    "\n",
    "    def create_all(self):\n",
    "        X_all = np.zeros((self.N_sequences, self.nt) + self.im_shape, np.float32)\n",
    "        for i, idx in enumerate(self.possible_starts):\n",
    "            vid_idx = np.random.choice(self.possible_starts)\n",
    "            X_all[i] = self.preprocess(self.X[idx, vid_idx:vid_idx+self.nt])\n",
    "        return X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dict['multitask'] == True:\n",
    "    train_generator = SequenceGenerator(train_data, data_dict['nt'] , train_label, data_dict, batch_size=data_dict['batch_size'], output_mode='error_and_label', n_classes=data_dict[\"nb_classes\"], shuffle=True, seed=seed)\n",
    "    val_generator = SequenceGenerator(val_data, data_dict['nt'] , val_label, data_dict, batch_size=data_dict['batch_size'], output_mode='error_and_label', n_classes=data_dict[\"nb_classes\"], shuffle=False, seed=seed)\n",
    "else:\n",
    "    train_generator = SequenceGenerator(train_data, data_dict['nt'] ,None, data_dict, batch_size=data_dict['batch_size'], n_classes=data_dict[\"nb_classes\"], shuffle=True, seed=seed)\n",
    "    val_generator = SequenceGenerator(val_data, data_dict['nt'] ,None, data_dict, batch_size=data_dict['batch_size'], n_classes=data_dict[\"nb_classes\"], shuffle=False, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X=(32, 18, 64, 64, 1) \t Y=(32, 18, 8)\n",
      "Label [[0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the generator output\n",
    "X, Y = next(val_generator)\n",
    "print(\"shapes X={} \\t Y={}\".format(X.shape, Y['label'].shape))\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, sharex=True, figsize=(nt*2,2))\n",
    "# plot X[0]\n",
    "X = X[0,:,:,:,0]\n",
    "ax.imshow(np.concatenate([t for t in X[:,:,:]], axis=1), interpolation='none', aspect=\"auto\")\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labelleft=False)\n",
    "ax.set_ylabel(r'X[0]', fontsize=10)\n",
    "ax.set_xlim(0,time_steps*im_width)\n",
    "\n",
    "print(\"Label\",Y['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = lambda e : data_dict['lr']*(1 - 0.1*(e//data_dict['lr_reduce_epoch'])) if e//data_dict['lr_reduce_epoch']<10 else 0.1*data_dict['lr']\n",
    "callbacks = [LearningRateScheduler(lr_schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dict['weight_dir']): \n",
    "    os.mkdir(data_dict['weight_dir'])\n",
    "    os.chmod(data_dict['weight_dir'], mode=0o777)\n",
    "callbacks.append(ModelCheckpoint(filepath=data_dict['weights_file'], monitor='val_loss', save_best_only=True))\n",
    "callbacks.append(EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=25, verbose=1,\n",
    "                      mode='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dict['json_file'], \"w\") as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = data_dict['samples_per_epoch']//data_dict['batch_size'] if data_dict['samples_per_epoch'] is not None else train_generator.n//data_dict['batch_size']\n",
    "validation_steps = int(data_dict['N_seq_val']/data_dict['batch_size']) if  data_dict['N_seq_val'] is not None else val_generator.n//data_dict['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "281/281 [==============================] - 430s - loss: 1.8717e-04 - y_loss: 1.8717e-04 - label_loss: 0.0000e+00 - y_mean_squared_error: 4.3768e-08 - label_acc: 0.1264 - val_loss: 1.2815e-04 - val_y_loss: 1.2815e-04 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 1.6862e-08 - val_label_acc: 0.1194\n",
      "Epoch 2/150\n",
      "281/281 [==============================] - 437s - loss: 1.1039e-04 - y_loss: 1.1039e-04 - label_loss: 0.0000e+00 - y_mean_squared_error: 1.2570e-08 - label_acc: 0.1291 - val_loss: 1.0249e-04 - val_y_loss: 1.0249e-04 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 1.0825e-08 - val_label_acc: 0.1284\n",
      "Epoch 3/150\n",
      "281/281 [==============================] - 434s - loss: 9.6333e-05 - y_loss: 9.6333e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 9.5927e-09 - label_acc: 0.1266 - val_loss: 9.0316e-05 - val_y_loss: 9.0316e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 8.4354e-09 - val_label_acc: 0.1197\n",
      "Epoch 4/150\n",
      "281/281 [==============================] - 426s - loss: 8.6176e-05 - y_loss: 8.6176e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 7.6904e-09 - label_acc: 0.1311 - val_loss: 8.0705e-05 - val_y_loss: 8.0705e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 6.7631e-09 - val_label_acc: 0.1198\n",
      "Epoch 5/150\n",
      "281/281 [==============================] - 427s - loss: 7.9376e-05 - y_loss: 7.9376e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 6.5362e-09 - label_acc: 0.1303 - val_loss: 7.5590e-05 - val_y_loss: 7.5590e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 5.9406e-09 - val_label_acc: 0.1211\n",
      "Epoch 6/150\n",
      "281/281 [==============================] - 437s - loss: 7.4723e-05 - y_loss: 7.4723e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 5.8214e-09 - label_acc: 0.1307 - val_loss: 7.4254e-05 - val_y_loss: 7.4254e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 5.7254e-09 - val_label_acc: 0.1181\n",
      "Epoch 7/150\n",
      "281/281 [==============================] - 436s - loss: 7.3788e-05 - y_loss: 7.3788e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 5.7320e-09 - label_acc: 0.1312 - val_loss: 6.8374e-05 - val_y_loss: 6.8374e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 4.8741e-09 - val_label_acc: 0.1203\n",
      "Epoch 8/150\n",
      "281/281 [==============================] - 415s - loss: 6.7822e-05 - y_loss: 6.7822e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 4.8030e-09 - label_acc: 0.1311 - val_loss: 6.5418e-05 - val_y_loss: 6.5418e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 4.4686e-09 - val_label_acc: 0.1194\n",
      "Epoch 9/150\n",
      "281/281 [==============================] - 436s - loss: 6.3913e-05 - y_loss: 6.3913e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 4.2694e-09 - label_acc: 0.1299 - val_loss: 6.3741e-05 - val_y_loss: 6.3741e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 4.2440e-09 - val_label_acc: 0.1202\n",
      "Epoch 10/150\n",
      "281/281 [==============================] - 438s - loss: 6.4071e-05 - y_loss: 6.4071e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 4.3087e-09 - label_acc: 0.1316 - val_loss: 6.0506e-05 - val_y_loss: 6.0506e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 3.8357e-09 - val_label_acc: 0.1188\n",
      "Epoch 11/150\n",
      "281/281 [==============================] - 434s - loss: 6.0951e-05 - y_loss: 6.0951e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 3.9008e-09 - label_acc: 0.1308 - val_loss: 6.0985e-05 - val_y_loss: 6.0985e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 3.8929e-09 - val_label_acc: 0.1179\n",
      "Epoch 12/150\n",
      "281/281 [==============================] - 417s - loss: 5.9099e-05 - y_loss: 5.9099e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 3.6691e-09 - label_acc: 0.1302 - val_loss: 5.7529e-05 - val_y_loss: 5.7529e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 3.4804e-09 - val_label_acc: 0.1208\n",
      "Epoch 13/150\n",
      "281/281 [==============================] - 440s - loss: 5.7799e-05 - y_loss: 5.7799e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 3.5278e-09 - label_acc: 0.1312 - val_loss: 5.6069e-05 - val_y_loss: 5.6069e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 3.3119e-09 - val_label_acc: 0.1224\n",
      "Epoch 14/150\n",
      "281/281 [==============================] - 438s - loss: 5.8723e-05 - y_loss: 5.8723e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 3.6567e-09 - label_acc: 0.1312 - val_loss: 5.7500e-05 - val_y_loss: 5.7500e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 3.4707e-09 - val_label_acc: 0.1167\n",
      "Epoch 15/150\n",
      "281/281 [==============================] - 428s - loss: 5.3931e-05 - y_loss: 5.3931e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 3.0742e-09 - label_acc: 0.1307 - val_loss: 5.3896e-05 - val_y_loss: 5.3896e-05 - val_label_loss: 0.0000e+00 - val_y_mean_squared_error: 3.0674e-09 - val_label_acc: 0.1216\n",
      "Epoch 16/150\n",
      "131/281 [============>.................] - ETA: 209s - loss: 5.3060e-05 - y_loss: 5.3060e-05 - label_loss: 0.0000e+00 - y_mean_squared_error: 2.9806e-09 - label_acc: 0.1283"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=data_dict['nb_epochs'],\n",
    "                              callbacks=callbacks, \n",
    "                              validation_data=val_generator, \n",
    "                              validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training history to a file\n",
    "with open(os.path.join(data_dict['result_dir'], 'training_history.json'), 'w') as f:\n",
    "    json.dump(history.history, f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading best model\n",
    "# data_dict['json_file'] = os.path.join(os.path.join(os.getcwd(), \"mnist_best_prednet\"), 'prednet_mnist_model.json')\n",
    "# data_dict['weights_file'] = os.path.join(os.path.join(os.getcwd(), \"mnist_best_prednet\"), 'prednet_mnist_weights.hdf5')\n",
    "\n",
    "# Loading trained model\n",
    "with open(data_dict['json_file'], 'r') as f:\n",
    "    json_string = f.read()\n",
    "\n",
    "model = model_from_json(json_string, custom_objects={'PredNet': PredNet, 'nb_layers':nb_layers})\n",
    "model.load_weights(data_dict['weights_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing model (to output predictions)\n",
    "layer_config = model.layers[1].get_config()\n",
    "if(data_dict[\"multitask\"]):\n",
    "    output_mode = 'prediction_and_label' \n",
    "else:\n",
    "    output_mode = 'prediction'\n",
    "layer_config['output_mode'] = output_mode\n",
    "data_format = layer_config['data_format'] if 'data_format' in layer_config else layer_config['dim_ordering']\n",
    "test_prednet = PredNet(weights=model.layers[1].get_weights(), **layer_config)\n",
    "input_shape = list(model.layers[0].batch_input_shape[1:])\n",
    "input_shape[0] = time_steps\n",
    "inputs = Input(shape=tuple(input_shape))\n",
    "predictions = test_prednet(inputs)\n",
    "test_model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #initialize lists for evaluation        \n",
    "mse_model_list, mse_prev_list, mae_model_list, mae_prev_list = ([] for i in range(4))\n",
    "psnr_list, ssim_list, sharpness_grad_list, psnr_prev_list, ssim_prev_list, sharpness_grad_prev_list = ([] for i in range(6))\n",
    "psnr_movement_list, psnr_movement_prev_list, ssim_movement_list, ssim_movement_prev_list =  ([] for i in range(4))\n",
    "conditioned_ssim_list, sharpness_list, sharpness_prev_list = ([] for i in range(3))\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO:  adhoc to speed things up \n",
    "data_dict['batch_size'] = 128\n",
    "max_test_batches = val_generator.n // 128 # adhoc, only run on few batches (/8)\n",
    "\n",
    "for index, data in enumerate(val_generator):\n",
    "    # Only consider steps_test number of steps\n",
    "    if index > max_test_batches:\n",
    "        break\n",
    "    # X_test = test_generator.next()[0]\n",
    "    X_test = data[0]        \n",
    "\n",
    "    if(data_dict['multitask']==True):\n",
    "        lbl = data[1]['label']\n",
    "        lbl_final = lbl.argmax(axis=-1)\n",
    "        X_hat_with_lbl = test_model.predict(X_test, data_dict['batch_size'])\n",
    "        X_hat, lbl_hat = X_hat_with_lbl[:,:,:-data_dict[\"nb_classes\"]], X_hat_with_lbl[:,:,-data_dict[\"nb_classes\"]:]\n",
    "        # print(\"<d>\", lbl_hat.shape, lbl_hat.max(), lbl_hat.min(), lbl_hat.mean())\n",
    "        X_hat  = np.reshape(X_hat, X_test.shape) \n",
    "#         lbl_pred_final_logits = np.moveaxis(lbl_hat,1,2).dot(get_exp_t_weights(time_steps)).squeeze()\n",
    "        lbl_pred_final = lbl_hat.argmax(axis=-1)\n",
    "        if index==0: \n",
    "            # visualize the predicted labels for the first round\n",
    "            for i in range(-data_dict['nt']-3,-data_dict['nt']):\n",
    "                print(\"\\nExpected labels  = \\n\", [directions[l] for l in lbl_final[i]]) \n",
    "                print(\"Predicted labels = \\n\", [directions[l] for l in lbl_pred_final[i]])\n",
    "        acc = (lbl_pred_final == lbl_final).mean()\n",
    "        print(\"{}, accuracy= {:.2f}%\".format(index, acc*100))\n",
    "        accuracy_list.append(acc)\n",
    "    else:\n",
    "        X_hat = test_model.predict(X_test, data_dict['batch_size'])\n",
    "    if data_format == 'channels_first':\n",
    "        X_test = np.transpose(X_test, (0, 1, 3, 4, 2))\n",
    "        X_hat = np.transpose(X_hat, (0, 1, 3, 4, 2))\n",
    "\n",
    "    # Compare the scores of PredNet predictions vs. using last frame.  Write results to prediction_scores.txt\n",
    "    # mean square error\n",
    "    mse_model_list.append(\n",
    "        np.mean((X_test[:, 1:] - X_hat[:, 1:]) ** 2))  # look at all timesteps except the first\n",
    "    mse_prev_list.append(np.mean((X_test[:, :-1] - X_test[:, 1:]) ** 2))\n",
    "    # mean absolute error\n",
    "    mae_model_list.append(\n",
    "        np.mean(np.abs(X_test[:, 1:] - X_hat[:, 1:])))\n",
    "    mae_prev_list.append(np.mean(np.abs(X_test[:, :-1] - X_test[:, 1:])))\n",
    "    # ssim\n",
    "    ssim_list.append(np.mean([return_difference(X_test[ind][1:], X_hat[ind][1:])[0] for ind in range(X_test.shape[0])]))\n",
    "    ssim_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[0] \n",
    "                                   for ind in range(X_test.shape[0]-1)]))\n",
    "    ssim_movement_list.append(np.mean([return_difference(X_test[ind], X_hat[ind])[2] \n",
    "                                       for ind in range(X_test.shape[0])]))\n",
    "    ssim_movement_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[2] \n",
    "                                   for ind in range(X_test.shape[0]-1)])) \n",
    "    conditioned_ssim_list.append(np.mean([conditioned_ssim(X_test[ind], X_hat[ind]) \n",
    "                                   for ind in range(X_test.shape[0])])) \n",
    "\n",
    "    # psnr\n",
    "    psnr_list.append(np.mean([return_difference(X_test[ind][1:], X_hat[ind][1:])[1] for ind in range(X_test.shape[0])]))            \n",
    "    psnr_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[1] \n",
    "                                   for ind in range(X_test.shape[0]-1)]))\n",
    "    psnr_movement_list.append(np.mean([return_difference(X_test[ind], X_hat[ind])[3] \n",
    "                                       for ind in range(X_test.shape[0])]))\n",
    "    psnr_movement_prev_list.append(np.mean([return_difference(X_test[ind][:-1], X_test[ind][1:])[3] \n",
    "                                   for ind in range(X_test.shape[0]-1)]))\n",
    "\n",
    "    # sharpness\n",
    "#     sharpness_grad_list.append(np.mean([sharpness_difference_grad(X_test[ind][1:], X_hat[ind][1:])\n",
    "#                                    for ind in range(X_test.shape[0])]))\n",
    "    #sharpness_grad_prev_list.append(np.mean([sharpness_difference_grad(X_test[ind][:-1], X_test[ind][1:])\n",
    "    #                                    for ind in range(X_test.shape[0]-1)]))\n",
    "\n",
    "#     sharpness_list.append(np.mean([sharpness_difference(X_test[ind][1:], X_hat[ind][1:])\n",
    "#                                   for ind in range(X_test.shape[0])]))\n",
    "    #sharpness_prev_list.append(np.mean([sharpness_difference(X_test[ind][:-1], X_test[ind][1:])\n",
    "    #                               for ind in range(X_test.shape[0])]))\n",
    "\n",
    "    \n",
    "# save in a dict and limit the size of float decimals to max 6\n",
    "results_dict = {                    \n",
    "\"MSE_mean\": float(\"{:.10f}\".format(np.mean(mse_model_list))), \n",
    "\"MSE_std\":float((\"{:.10f}\".format(np.std(mse_model_list)))), \n",
    "\"MSE_mean_prev_frame_copy\":float(\"{:.10f}\".format(np.mean(mse_prev_list))), \n",
    "\"MSE_std_prev_frame_copy\":float(\"{:.10f}\".format(np.std(mse_prev_list))),\n",
    "\"MAE_mean\": float(\"{:.6f}\".format(np.mean(mae_model_list))), \n",
    "\"MAE_std\":float((\"{:.6f}\".format(np.std(mae_model_list)))), \n",
    "\"MAE_mean_prev_frame_copy\":float(\"{:.6f}\".format(np.mean(mae_prev_list))), \n",
    "\"MAE_std_prev_frame_copy\":float(\"{:.6f}\".format(np.std(mae_prev_list))),\n",
    "\"SSIM_mean\": float(\"{:.6f}\".format(np.mean(ssim_list))), \n",
    "\"SSIM_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(ssim_prev_list))), \n",
    "\"SSIM_movement_mean\": float(\"{:.6f}\".format(np.mean(ssim_movement_list))), \n",
    "\"SSIM_movement_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(ssim_movement_prev_list))), \n",
    "\"Conditioned_SSIM_mean\": float(\"{:.6f}\".format(np.mean(conditioned_ssim_list))),\n",
    "\"PSNR_mean\": float(\"{:.6f}\".format(np.mean(psnr_list))),\n",
    "\"PSNR_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(psnr_prev_list))), \n",
    "\"PSNR_movement_mean\": float(\"{:.6f}\".format(np.mean(psnr_movement_list))), \n",
    "\"PSNR_movement_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(psnr_movement_prev_list))), \n",
    "\"Sharpness_grad_mean\": float(\"{:.6f}\".format(np.mean(sharpness_grad_list))),\n",
    "#\"Sharpness_grad_mean_prev_frame_copy\": float(\"{:.6f}\".format(np.mean(sharpness_grad_prev_list))),\n",
    "\"Sharpness_difference_mean\": float(\"{:.6f}\".format(np.mean(sharpness_list)))\n",
    "#\"Sharpness_difference_mean_prev_frame_copy\" : float(\"{:.6f}\".format(np.mean(sharpness_prev_list)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model results for training dataset:\")\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['MSE_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dict['result_dir'], 'mnist_scores.json'), 'w') as f:\n",
    "    json.dump(results_dict, f, sort_keys=True,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating extra plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_plot_flag = False\n",
    "\n",
    "plot_save_dir = os.path.join(data_dict['result_dir'], 'predictions')\n",
    "if not os.path.exists(plot_save_dir):\n",
    "    os.makedirs(plot_save_dir)\n",
    "\n",
    "assert X_test.shape==X_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extra_plot_flag:\n",
    "    #Create models for error and R plots\n",
    "    extra_test_models = []\n",
    "    no_layers = len(test_prednet.stack_sizes)\n",
    "    extra_output_modes = (['E'+str(no) for no in range(no_layers)] + ['A'+str(no) for no in range(no_layers)] \n",
    "                        + ['Ahat'+str(no) for no in range(no_layers)] + ['R'+str(no) for no in range(no_layers)])\n",
    "\n",
    "    for output_mode in extra_output_modes:\n",
    "        if(data_dict['multitask'] == True):\n",
    "            output_mode += \"_and_label\"\n",
    "        layer_config['output_mode'] = output_mode    \n",
    "        data_format = (layer_config['data_format'] if 'data_format' in layer_config \n",
    "                        else layer_config['dim_ordering'])\n",
    "        extra_test_prednet = PredNet(weights=model.layers[1].get_weights(), **layer_config)\n",
    "        input_shape = list(model.layers[0].batch_input_shape[1:])\n",
    "        input_shape[0] = data_dict['nt']\n",
    "        inputs = Input(shape=tuple(input_shape))\n",
    "        extra_predictions = extra_test_prednet(inputs)\n",
    "        extra_test_model = Model(inputs=inputs, outputs=extra_predictions)\n",
    "        extra_test_models.append((extra_test_model, output_mode))\n",
    "    \n",
    "    #Create outputs for extra plots\n",
    "    error_X_hats = []\n",
    "    R_X_hats = []\n",
    "    A_X_hats = []\n",
    "    Ahat_X_hats = []\n",
    "    for test_model, output_mode in extra_test_models:\n",
    "        if output_mode[0]=='R':\n",
    "            R_X_hat = test_model.predict(X_test) \n",
    "            R_X_hats.append((R_X_hat, output_mode))\n",
    "        elif output_mode[0]=='E':\n",
    "            error_X_hat = test_model.predict(X_test) \n",
    "            error_X_hats.append((error_X_hat, output_mode))\n",
    "        elif 'Ahat' in output_mode: \n",
    "            Ahat_X_hat = test_model.predict(X_test) \n",
    "            Ahat_X_hats.append((Ahat_X_hat, output_mode))\n",
    "        else: # output_mode[0]=='A':\n",
    "            A_X_hat = test_model.predict(X_test) \n",
    "            A_X_hats.append((A_X_hat, output_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample 'plots_per_grp' videos from each sub-group\n",
    "aspect_ratio = float(X_hat.shape[2]) / X_hat.shape[3]\n",
    "for i in range(3):      #len(X_test)    \n",
    "    if extra_plot_flag:\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=20, sharex=True, figsize=(time_steps, 25 * aspect_ratio),\n",
    "                              gridspec_kw={'height_ratios':[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,3,3]})\n",
    "    else:\n",
    "        fig, ax = plt.subplots(ncols=1, nrows=2, sharex=True, figsize=(time_steps, 2 * aspect_ratio))\n",
    "\n",
    "    # set the title of the plot as the label and the video ID for reference\n",
    "    if(data_dict['multitask']):\n",
    "        title = \"{}) TRUE {}\\n PRED: {}\".format(\n",
    "        i, \n",
    "        [directions[lbl] for lbl in lbl_final[i]],\n",
    "        [directions[lbl] for lbl in lbl_pred_final[i]])\n",
    "    else:\n",
    "        title = \"{}) Digit {}\".format( # Pos {}\n",
    "        i, \n",
    "        np.unique(val_label[i,0,:,0].astype(int))\n",
    "#         ,val_label[i,:,0,1:]\n",
    ")\n",
    "\n",
    "    fig.suptitle(title, fontsize=10)\n",
    "\n",
    "    #Plot video\n",
    "    ax = plt.subplot()\n",
    "    ax.imshow(np.concatenate([t for t in X_test[i,:,:,:,0]], axis=1), interpolation='none', aspect=\"auto\")\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False,\n",
    "                                    labelbottom=False, labelleft=False)\n",
    "    ax.set_ylabel(r'Actual', fontsize=10)\n",
    "    ax.set_xlim(0,time_steps*im_width)\n",
    "\n",
    "    #Plot predictions\n",
    "    divider = make_axes_locatable(ax)\n",
    "    ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                             \n",
    "    ax.imshow(np.concatenate([t for t in X_hat[i,:,:,:,0]], axis=1), interpolation='none', aspect=\"auto\")\n",
    "    ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False,\n",
    "                                    labelbottom=False, labelleft=False)\n",
    "    ax.set_ylabel(r'Prediction', fontsize=10)\n",
    "    ax.set_xlim(0,time_steps*im_width)\n",
    "    \n",
    "    if extra_plot_flag:\n",
    "        #Create values for R plots      \n",
    "        results = plot_changes_in_r(R_X_hats, i, std_param=data_dict['std_param'])\n",
    "        ax = divider.append_axes(\"bottom\", size=\"300%\", pad=0.2)                                                                \n",
    "        #Plot R plots\n",
    "        for layer in results:\n",
    "            (y,x,std) = layer[0]\n",
    "            x = [im_width/2+item*im_width for item in x]\n",
    "            ax.fill_between(x, [(val-data_dict['std_param']*dev) for val,dev in zip(y,std)], \n",
    "                             [(val+data_dict['std_param']*dev) for val,dev in zip(y,std)], alpha=0.1)\n",
    "            ax.plot(x, y)\n",
    "\n",
    "        ax.set_xlim(0,time_steps*im_width)\n",
    "        ax.set_xticks(np.arange(im_width/2, time_steps*im_width, step=im_width))                \n",
    "        ax.set_xticklabels(np.arange(1,time_steps+1))\n",
    "        ax.grid(True)                  \n",
    "        ax.set_ylabel(r\"Mean R activations\", fontsize=10)\n",
    "        ax.xaxis.set_label_position('top') \n",
    "        ax.legend(['R'+str(no) for no in range(no_layers)], loc='center left')\n",
    "\n",
    "        #Create values for E plots      \n",
    "        results = plot_changes_in_r(error_X_hats, i, std_param=data_dict['std_param'])\n",
    "        ax = divider.append_axes(\"bottom\", size=\"300%\", pad=0.2)                                                                \n",
    "        #Plot E plots\n",
    "        for layer in results:\n",
    "            (y,x,std) = layer[0]\n",
    "            x = [im_width/2+item*im_width for item in x]\n",
    "            ax.fill_between(x, [(val-data_dict['std_param']*dev) for val,dev in zip(y,std)], \n",
    "                            [(val+data_dict['std_param']*dev) for val,dev in zip(y,std)], alpha=0.1)\n",
    "            ax.plot(x, y)\n",
    "\n",
    "        ax.set_xlim(0,time_steps*im_width)\n",
    "        ax.set_xticks(np.arange(im_width/2, time_steps*im_width, step=im_width))                \n",
    "        ax.set_xticklabels(np.arange(1,time_steps+1))\n",
    "        ax.grid(True)                  \n",
    "        ax.set_ylabel(r\"Mean E activations\", fontsize=10)\n",
    "        ax.xaxis.set_label_position('top') \n",
    "        ax.legend(['E'+str(no) for no in range(no_layers)], loc='center left')\n",
    "\n",
    "        #Create error output matrices to plot inside the next loop\n",
    "        R_matrices = plot_errors(R_X_hats, X_test, ind=i)\n",
    "        A_matrices =  plot_errors(A_X_hats, X_test, ind=i) \n",
    "        Ahat_matrices = plot_errors(Ahat_X_hats, X_test, ind=i)\n",
    "        error_matrices = plot_errors(error_X_hats, X_test, ind=i)\n",
    "        #Plot R, A, Ahat and errors for each layer\n",
    "        for layer in range(len(error_matrices)):   \n",
    "                ##R\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.2)                                             \n",
    "                ax.imshow(np.concatenate([t for t in R_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"R\" + str(layer), fontsize=10)\n",
    "                ax.set_xlabel(r\"Layer \" + str(layer), fontsize=10)\n",
    "                ax.xaxis.set_label_position('top') \n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "                ##A\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                             \n",
    "                ax.imshow(np.concatenate([t for t in Ahat_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"Ahat\" + str(layer), fontsize=10)\n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "                ##Ahat\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                     \n",
    "                ax.imshow(np.concatenate([t for t in A_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"A\" + str(layer), fontsize=10)\n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "                ##E\n",
    "                ax = divider.append_axes(\"bottom\", size=\"100%\", pad=0.0)                                             \n",
    "                ax.imshow(np.concatenate([t for t in error_matrices[layer]], axis=1), \n",
    "                                   interpolation='nearest', cmap='gray', aspect=\"auto\")\n",
    "                ax.tick_params(axis='both', which='both', bottom=False, top=False, left=False, \n",
    "                                        right=False, labelbottom=False, labelleft=False)\n",
    "                ax.set_ylabel(r\"E\" + str(layer), fontsize=10)\n",
    "                ax.set_xlim(0,time_steps*im_width)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(plot_save_dir+\"/\"+\"prediction\"+str(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
